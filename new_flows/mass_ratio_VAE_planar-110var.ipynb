{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy as sp\n",
    "import scipy.stats\n",
    "import itertools\n",
    "import logging\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import torch.utils.data as utils\n",
    "import math\n",
    "import time\n",
    "import tqdm\n",
    "\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from argparse import ArgumentParser\n",
    "from torch.distributions import MultivariateNormal\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.init as init\n",
    "\n",
    "from flows import RealNVP, Planar\n",
    "from models import NormalizingFlowModel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load and process the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "mode = 'ROC'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "f_rnd = pd.read_hdf(\"/data/t3home000/spark/QUASAR/preprocessing/nsubjettiness_massratio_rnd.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Mjj</th>\n",
       "      <th>Mj1</th>\n",
       "      <th>j1 tau1(b=.5)</th>\n",
       "      <th>j1 tau1(b=1)</th>\n",
       "      <th>j1 tau1(b=2)</th>\n",
       "      <th>j1 tau2(b=.5)</th>\n",
       "      <th>j1 tau2(b=1)</th>\n",
       "      <th>j1 tau2(b=2)</th>\n",
       "      <th>j1 tau3(b=.5)</th>\n",
       "      <th>j1 tau3(b=1)</th>\n",
       "      <th>...</th>\n",
       "      <th>j2 tau15(b=2)</th>\n",
       "      <th>j2 n_trk</th>\n",
       "      <th>j2 pT1</th>\n",
       "      <th>j2 M_trim</th>\n",
       "      <th>j2 M_prun</th>\n",
       "      <th>j2 M_mmdt</th>\n",
       "      <th>j2 M_sdb1</th>\n",
       "      <th>j2 M_sdb2</th>\n",
       "      <th>j2 M_sdm1</th>\n",
       "      <th>isSignal</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2577.571899</td>\n",
       "      <td>98.677270</td>\n",
       "      <td>0.053375</td>\n",
       "      <td>0.022677</td>\n",
       "      <td>0.009253</td>\n",
       "      <td>0.042518</td>\n",
       "      <td>0.011994</td>\n",
       "      <td>0.002307</td>\n",
       "      <td>0.038869</td>\n",
       "      <td>0.009455</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000051</td>\n",
       "      <td>128.0</td>\n",
       "      <td>1282.286017</td>\n",
       "      <td>42.162664</td>\n",
       "      <td>18.466533</td>\n",
       "      <td>18.466533</td>\n",
       "      <td>31.845136</td>\n",
       "      <td>42.162664</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3807.507389</td>\n",
       "      <td>584.595432</td>\n",
       "      <td>0.670141</td>\n",
       "      <td>0.490678</td>\n",
       "      <td>0.275638</td>\n",
       "      <td>0.331875</td>\n",
       "      <td>0.169591</td>\n",
       "      <td>0.060717</td>\n",
       "      <td>0.231046</td>\n",
       "      <td>0.078599</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001876</td>\n",
       "      <td>348.0</td>\n",
       "      <td>1306.137883</td>\n",
       "      <td>395.226881</td>\n",
       "      <td>393.309512</td>\n",
       "      <td>405.034096</td>\n",
       "      <td>405.034096</td>\n",
       "      <td>405.034096</td>\n",
       "      <td>405.034096</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1710.965414</td>\n",
       "      <td>159.597526</td>\n",
       "      <td>0.418784</td>\n",
       "      <td>0.241483</td>\n",
       "      <td>0.100078</td>\n",
       "      <td>0.343810</td>\n",
       "      <td>0.163651</td>\n",
       "      <td>0.051971</td>\n",
       "      <td>0.258793</td>\n",
       "      <td>0.113035</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001236</td>\n",
       "      <td>236.0</td>\n",
       "      <td>1072.462085</td>\n",
       "      <td>54.235070</td>\n",
       "      <td>41.967840</td>\n",
       "      <td>41.352112</td>\n",
       "      <td>51.721630</td>\n",
       "      <td>70.442364</td>\n",
       "      <td>-0.000003</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2603.379037</td>\n",
       "      <td>515.237299</td>\n",
       "      <td>0.483659</td>\n",
       "      <td>0.435741</td>\n",
       "      <td>0.230891</td>\n",
       "      <td>0.141166</td>\n",
       "      <td>0.039669</td>\n",
       "      <td>0.008714</td>\n",
       "      <td>0.114992</td>\n",
       "      <td>0.031118</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001400</td>\n",
       "      <td>352.0</td>\n",
       "      <td>1217.031950</td>\n",
       "      <td>81.842001</td>\n",
       "      <td>60.307703</td>\n",
       "      <td>60.307703</td>\n",
       "      <td>72.423677</td>\n",
       "      <td>84.480859</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3294.162200</td>\n",
       "      <td>142.420213</td>\n",
       "      <td>0.203619</td>\n",
       "      <td>0.087964</td>\n",
       "      <td>0.026577</td>\n",
       "      <td>0.149224</td>\n",
       "      <td>0.044661</td>\n",
       "      <td>0.006325</td>\n",
       "      <td>0.091160</td>\n",
       "      <td>0.023344</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000491</td>\n",
       "      <td>204.0</td>\n",
       "      <td>1205.343324</td>\n",
       "      <td>103.456059</td>\n",
       "      <td>99.817788</td>\n",
       "      <td>103.456059</td>\n",
       "      <td>103.456059</td>\n",
       "      <td>103.456059</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 110 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           Mjj         Mj1  j1 tau1(b=.5)  j1 tau1(b=1)  j1 tau1(b=2)  \\\n",
       "0  2577.571899   98.677270       0.053375      0.022677      0.009253   \n",
       "1  3807.507389  584.595432       0.670141      0.490678      0.275638   \n",
       "2  1710.965414  159.597526       0.418784      0.241483      0.100078   \n",
       "3  2603.379037  515.237299       0.483659      0.435741      0.230891   \n",
       "4  3294.162200  142.420213       0.203619      0.087964      0.026577   \n",
       "\n",
       "   j1 tau2(b=.5)  j1 tau2(b=1)  j1 tau2(b=2)  j1 tau3(b=.5)  j1 tau3(b=1)  \\\n",
       "0       0.042518      0.011994      0.002307       0.038869      0.009455   \n",
       "1       0.331875      0.169591      0.060717       0.231046      0.078599   \n",
       "2       0.343810      0.163651      0.051971       0.258793      0.113035   \n",
       "3       0.141166      0.039669      0.008714       0.114992      0.031118   \n",
       "4       0.149224      0.044661      0.006325       0.091160      0.023344   \n",
       "\n",
       "   ...  j2 tau15(b=2)  j2 n_trk       j2 pT1   j2 M_trim   j2 M_prun  \\\n",
       "0  ...       0.000051     128.0  1282.286017   42.162664   18.466533   \n",
       "1  ...       0.001876     348.0  1306.137883  395.226881  393.309512   \n",
       "2  ...       0.001236     236.0  1072.462085   54.235070   41.967840   \n",
       "3  ...       0.001400     352.0  1217.031950   81.842001   60.307703   \n",
       "4  ...       0.000491     204.0  1205.343324  103.456059   99.817788   \n",
       "\n",
       "    j2 M_mmdt   j2 M_sdb1   j2 M_sdb2   j2 M_sdm1  isSignal  \n",
       "0   18.466533   31.845136   42.162664    0.000000       0.0  \n",
       "1  405.034096  405.034096  405.034096  405.034096       0.0  \n",
       "2   41.352112   51.721630   70.442364   -0.000003       0.0  \n",
       "3   60.307703   72.423677   84.480859    0.000003       0.0  \n",
       "4  103.456059  103.456059  103.456059    0.000008       1.0  \n",
       "\n",
       "[5 rows x 110 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f_rnd.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "if mode == 'ROC':\n",
    "    dt = f_rnd.values\n",
    "else:\n",
    "    dt_PureBkg = dt_PureBkg = f_PureBkg.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.concatenate((dt[:,1:48], dt[:,55:102]), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "76"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f_rnd.columns.get_loc(\"j2 tau7(b=2)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1100000, 94)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(94):\n",
    "    X[:,i] = (X[:,i]-np.mean(X[:,i]))/np.std(X[:,i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = dt[:,-1]\n",
    "bkg_idx = np.where(idx==0)[0]\n",
    "signal_idx = np.where(idx==1)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_PureBkg = torch.tensor(X[bkg_idx])\n",
    "\n",
    "total_PureBkg_selection = total_PureBkg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1000000, 94])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_PureBkg_selection.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "bs = 256\n",
    "bkgAE_train_iterator = utils.DataLoader(total_PureBkg_selection, batch_size=bs, shuffle=True) \n",
    "bkgAE_test_iterator = utils.DataLoader(total_PureBkg_selection, batch_size=bs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VAE_NF(nn.Module):\n",
    "    def __init__(self, K, D):\n",
    "        super().__init__()\n",
    "        self.dim = D\n",
    "        self.K = K\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Linear(94, 64),\n",
    "            nn.LeakyReLU(True),\n",
    "            nn.Linear(64, 48),\n",
    "            nn.LeakyReLU(True),            \n",
    "            nn.Linear(48, D * 2)\n",
    "        )\n",
    "\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(D, 48),\n",
    "            nn.LeakyReLU(True),\n",
    "            nn.Linear(48, 64),\n",
    "            nn.LeakyReLU(True),\n",
    "            nn.Linear(64, 94),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "        \n",
    "        flow_init = Planar(dim=D)\n",
    "        flows_init = [flow_init for _ in range(K)]\n",
    "        prior = MultivariateNormal(torch.zeros(D).cuda(), torch.eye(D).cuda())\n",
    "        self.flows = NormalizingFlowModel(prior, flows_init)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Run Encoder and get NF params\n",
    "        enc = self.encoder(x)\n",
    "        mu = enc[:, :self.dim]\n",
    "        log_var = enc[:, self.dim: self.dim * 2]\n",
    "\n",
    "        # Re-parametrize\n",
    "        sigma = (log_var * .5).exp()\n",
    "        z = mu + sigma * torch.randn_like(sigma)\n",
    "        kl_div = -0.5 * torch.sum(1 + log_var - mu.pow(2) - log_var.exp())\n",
    "        # Construct more expressive posterior with NF\n",
    "        \n",
    "        z_k, _, sum_ladj = self.flows(z)\n",
    "        \n",
    "        kl_div = kl_div / x.size(0) - sum_ladj.mean()  # mean over batch\n",
    "\n",
    "        # Run Decoder\n",
    "        x_prime = self.decoder(z_k)\n",
    "        return x_prime, kl_div"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating Instance¶"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_EPOCHS = 10\n",
    "PRINT_INTERVAL = 2000\n",
    "NUM_WORKERS = 4\n",
    "LR = 1e-4\n",
    "\n",
    "N_FLOWS = 1\n",
    "Z_DIM = 2\n",
    "\n",
    "n_steps = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = VAE_NF(N_FLOWS, Z_DIM).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(model.parameters(), lr=LR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train():\n",
    "    global n_steps\n",
    "    train_loss = []\n",
    "    model.train()\n",
    "\n",
    "    for batch_idx, x in enumerate(bkgAE_train_iterator):\n",
    "        start_time = time.time()\n",
    "        \n",
    "        x = x.float().cuda()\n",
    "\n",
    "        x_tilde, kl_div = model(x)\n",
    "        loss_recons = F.binary_cross_entropy(x_tilde, x, size_average=False) / x.size(0)\n",
    "        loss = loss_recons + kl_div\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        train_loss.append([loss_recons.item(), kl_div.item()])\n",
    "\n",
    "        if (batch_idx + 1) % PRINT_INTERVAL == 0:\n",
    "            print('\\tIter [{}/{} ({:.0f}%)]\\tLoss: {} Time: {:5.3f} ms/batch'.format(\n",
    "                batch_idx * len(x), 50000,\n",
    "                PRINT_INTERVAL * batch_idx / 50000,\n",
    "                np.asarray(train_loss)[-PRINT_INTERVAL:].mean(0),\n",
    "                1000 * (time.time() - start_time)\n",
    "            ))\n",
    "\n",
    "        n_steps += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(split='valid'):\n",
    "    global n_steps\n",
    "    start_time = time.time()\n",
    "    val_loss = []\n",
    "    model.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, x in enumerate(bkgAE_test_iterator):\n",
    "            \n",
    "            x = x.float().cuda()\n",
    "\n",
    "            x_tilde, kl_div = model(x)\n",
    "            loss_recons = F.binary_cross_entropy(x_tilde, x, size_average=False) / x.size(0)\n",
    "            loss = loss_recons + kl_div\n",
    "\n",
    "            val_loss.append(loss.item())\n",
    "            #writer.add_scalar('loss/{}/ELBO'.format(split), loss.item(), n_steps)\n",
    "            #writer.add_scalar('loss/{}/reconstruction'.format(split), loss_recons.item(), n_steps)\n",
    "            #writer.add_scalar('loss/{}/KL'.format(split), kl_div.item(), n_steps)\n",
    "\n",
    "    print('\\nEvaluation Completed ({})!\\tLoss: {:5.4f} Time: {:5.3f} s'.format(\n",
    "        split,\n",
    "        np.asarray(val_loss).mean(0),\n",
    "        time.time() - start_time\n",
    "    ))\n",
    "    return np.asarray(val_loss).mean(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VAE_NF(\n",
      "  (encoder): Sequential(\n",
      "    (0): Linear(in_features=94, out_features=64, bias=True)\n",
      "    (1): LeakyReLU(negative_slope=True)\n",
      "    (2): Linear(in_features=64, out_features=48, bias=True)\n",
      "    (3): LeakyReLU(negative_slope=True)\n",
      "    (4): Linear(in_features=48, out_features=4, bias=True)\n",
      "  )\n",
      "  (decoder): Sequential(\n",
      "    (0): Linear(in_features=2, out_features=48, bias=True)\n",
      "    (1): LeakyReLU(negative_slope=True)\n",
      "    (2): Linear(in_features=48, out_features=64, bias=True)\n",
      "    (3): LeakyReLU(negative_slope=True)\n",
      "    (4): Linear(in_features=64, out_features=94, bias=True)\n",
      "    (5): Sigmoid()\n",
      "  )\n",
      "  (flows): NormalizingFlowModel(\n",
      "    (flows): ModuleList(\n",
      "      (0): Planar()\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/spark/miniconda3/envs/myenv/lib/python3.6/site-packages/torch/nn/_reduction.py:43: UserWarning: size_average and reduce args will be deprecated, please use reduction='sum' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tIter [511744/50000 (80%)]\tLoss: [-1241.298494     35.3012257] Time: 5.805 ms/batch\n",
      "\n",
      "Evaluation Completed (valid)!\tLoss: -1805.3061 Time: 6.349 s\n",
      "Saving model!\n",
      "Epoch 2:\n",
      "\tIter [511744/50000 (80%)]\tLoss: [-1882.40807227     9.31075751] Time: 5.571 ms/batch\n",
      "\n",
      "Evaluation Completed (valid)!\tLoss: -1965.3503 Time: 6.296 s\n",
      "Saving model!\n",
      "Epoch 3:\n",
      "\tIter [511744/50000 (80%)]\tLoss: [-1973.18166119     7.0826777 ] Time: 4.365 ms/batch\n",
      "\n",
      "Evaluation Completed (valid)!\tLoss: -1943.7796 Time: 6.190 s\n",
      "Not saving model! Last saved: 2\n",
      "Epoch 4:\n",
      "\tIter [511744/50000 (80%)]\tLoss: [-1969.90268256     6.77202928] Time: 4.616 ms/batch\n",
      "\n",
      "Evaluation Completed (valid)!\tLoss: -1957.9665 Time: 6.265 s\n",
      "Not saving model! Last saved: 2\n",
      "Epoch 5:\n",
      "\tIter [511744/50000 (80%)]\tLoss: [-1956.96183716     6.80509357] Time: 4.450 ms/batch\n",
      "\n",
      "Evaluation Completed (valid)!\tLoss: -1918.9948 Time: 6.381 s\n",
      "Not saving model! Last saved: 2\n",
      "Epoch 6:\n",
      "\tIter [511744/50000 (80%)]\tLoss: [-1920.74120068     6.93271254] Time: 4.431 ms/batch\n",
      "\n",
      "Evaluation Completed (valid)!\tLoss: -1885.1508 Time: 6.293 s\n",
      "Not saving model! Last saved: 2\n",
      "Epoch 7:\n",
      "\tIter [511744/50000 (80%)]\tLoss: [-1854.76761664     7.11553461] Time: 4.354 ms/batch\n",
      "\n",
      "Evaluation Completed (valid)!\tLoss: -1771.9925 Time: 6.288 s\n",
      "Not saving model! Last saved: 2\n",
      "Patience Limit Reached\n"
     ]
    }
   ],
   "source": [
    "N_EPOCHS = 10\n",
    "BEST_LOSS = 99999\n",
    "LAST_SAVED = -1\n",
    "PATIENCE_COUNT = 0\n",
    "PATIENCE_LIMIT = 5\n",
    "for epoch in range(1, 10):\n",
    "    print(\"Epoch {}:\".format(epoch))\n",
    "    train()\n",
    "    cur_loss = evaluate()\n",
    "\n",
    "    if cur_loss <= BEST_LOSS:\n",
    "        PATIENCE_COUNT = 0\n",
    "        BEST_LOSS = cur_loss\n",
    "        LAST_SAVED = epoch\n",
    "        print(\"Saving model!\")\n",
    "        if mode == 'ROC':\n",
    "            torch.save(model.state_dict(),\"/data/t3home000/spark/QUASAR/weights/bkg_vae_NF_planar_RND_110var.h5\")\n",
    "        else:\n",
    "            torch.save(model.state_dict(), \"/data/t3home000/spark/QUASAR/weights/bkg_vae_NF_planar_PureBkg_22var.h5\")\n",
    "    else:\n",
    "        PATIENCE_COUNT += 1\n",
    "        print(\"Not saving model! Last saved: {}\".format(LAST_SAVED))\n",
    "        if PATIENCE_COUNT > 4:\n",
    "            print(\"Patience Limit Reached\")\n",
    "            break "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_state_dict(torch.load(\"/data/t3home000/spark/QUASAR/weights/bkg_vae_NF_planar_RND_110var.h5\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing with the trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_loss(dt):\n",
    "    print(dt.shape)\n",
    "    \n",
    "    #for i in index_list:\n",
    "    #    print(i)\n",
    "    #    dt[:,i] = (dt[:,i]-np.mean(dt[:,i]))/np.std(dt[:,i])\n",
    "  \n",
    "    \n",
    "    total_in = torch.tensor(dt)\n",
    "    #total_in_train_x_1 = total_in.t()[0:6].t()\n",
    "    #total_in_train_x_3 = total_in.t()[7:13].t()\n",
    "    total_in_selection = total_in\n",
    "    #z_mu, z_var  = model.enc(total_in_selection.float().cuda())\n",
    "    #x_sample, z_mu, z_var = model(total_in_selection.float().cuda())\n",
    "    #std = torch.exp(z_var / 2)\n",
    "    #eps = torch.randn_like(std)\n",
    "    #x_sample = eps.mul(std).add_(z_mu)\n",
    "    #decoded_bkg = model.dec(x_sample)\n",
    "    #recon_loss = np.zeros(len(dt),dtype=np.float)\n",
    "    #for i in range(len(dt)):\n",
    "    #    recon_loss[i] = F.binary_cross_entropy(x_sample[i].float().cuda(), total_in_selection[i].float().cuda(), size_average=False).data.cpu().numpy()\n",
    "    \n",
    "    #loss_bkg = torch.mean((x_sample.float().cuda()-total_in_selection.float().cuda())**2,dim=1).data.cpu().numpy()\n",
    "\n",
    "\n",
    "    \n",
    "    with torch.no_grad():\n",
    "         #reconstruction loss\n",
    "        #x_sample, z_mu, z_var = model(total_in_selection.float().cuda())\n",
    "        #recon_loss = F.binary_cross_entropy(x_sample, total_in_selection.float().cuda(), size_average=False, reduce=None)\n",
    "        \n",
    "\n",
    "        #kl divergence loss\n",
    "        #kl_loss = 0.5 * torch.sum(torch.exp(z_var) + z_mu**2 - 1.0 - z_var)\n",
    "\n",
    "        #total loss\n",
    "        #loss = recon_loss + kl_loss\n",
    "        loss = torch.mean((model(total_in_selection.float().cuda())[0]- total_in_selection.float().cuda())**2,dim=1).data.cpu().numpy()\n",
    "    \n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100000, 94)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[signal_idx].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000000, 94)\n",
      "(100000, 94)\n"
     ]
    }
   ],
   "source": [
    "loss_bkg = get_loss(X[bkg_idx])\n",
    "loss_sig = get_loss(X[signal_idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.rcParams[\"figure.figsize\"] = (10,10)\n",
    "bins = np.linspace(0,3,1100)\n",
    "plt.hist(loss_bkg,bins=bins,alpha=0.3,color='b',label='bkg')\n",
    "plt.hist(loss_sig,bins=bins,alpha=0.3,color='r',label='sig')\n",
    "plt.xlabel(r'Autoencoder Loss')\n",
    "plt.ylabel('Count')\n",
    "plt.legend(loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tpr_fpr(sigloss,bkgloss,aetype='sig'):\n",
    "    bins = np.linspace(0,50,1001)\n",
    "    tpr = []\n",
    "    fpr = []\n",
    "    for cut in bins:\n",
    "        if aetype == 'sig':\n",
    "            tpr.append(np.where(sigloss<cut)[0].shape[0]/len(sigloss))\n",
    "            fpr.append(np.where(bkgloss<cut)[0].shape[0]/len(bkgloss))\n",
    "        if aetype == 'bkg':\n",
    "            tpr.append(np.where(sigloss>cut)[0].shape[0]/len(sigloss))\n",
    "            fpr.append(np.where(bkgloss>cut)[0].shape[0]/len(bkgloss))\n",
    "    return tpr,fpr        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bkg_tpr, bkg_fpr = get_tpr_fpr(loss_sig,loss_bkg,aetype='bkg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('NFLOWVAE_PlanarNEW_bkgAE_fpr.npy',bkg_fpr)\n",
    "np.save('NFLOWVAE_PlanarNEW_bkgAE_tpr.npy',bkg_tpr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(bkg_fpr,bkg_tpr,label='Bkg NFlowVAE-Planar')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_precision_recall(sigloss,bkgloss,aetype='bkg'):\n",
    "    bins = np.linspace(0,100,1001)\n",
    "    tpr = []\n",
    "    fpr = []\n",
    "    precision = []\n",
    "    for cut in bins:\n",
    "        if aetype == 'sig':\n",
    "            tpr.append(np.where(sigloss<cut)[0].shape[0]/len(sigloss))\n",
    "            precision.append((np.where(sigloss<cut)[0].shape[0])/(np.where(bkgloss<cut)[0].shape[0]+np.where(sigloss<cut)[0].shape[0]))\n",
    "            \n",
    "        if aetype == 'bkg':\n",
    "            tpr.append(np.where(sigloss>cut)[0].shape[0]/len(sigloss))\n",
    "            precision.append((np.where(sigloss>cut)[0].shape[0])/(np.where(bkgloss>cut)[0].shape[0]+np.where(sigloss>cut)[0].shape[0]))\n",
    "    return precision,tpr      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "precision,recall = get_precision_recall(loss_sig,loss_bkg,aetype='bkg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('NFLOWVAE_PlanarNEW_22var_sigloss.npy',loss_sig)\n",
    "np.save('NFLOWVAE_PlanarNEW_22var_bkgloss.npy',loss_bkg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('NFLOWVAE_PlanarNEW_precision.npy',precision)\n",
    "np.save('NFLOWVAE_PlanarNEW_recall.npy',recall)\n",
    "np.save('NFLOWVAE_PlanarNEW_bkgAE_fpr.npy',bkg_fpr)\n",
    "np.save('NFLOWVAE_PlanarNEW_bkgAE_tpr.npy',bkg_tpr)\n",
    "np.save('NFLOWVAE_PlanarNEW_sigloss.npy',loss_sig)\n",
    "np.save('NFLOWVAE_PlanarNEW_bkgloss.npy',loss_bkg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(recall,precision)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flows = [1,2,3,4,5,6]\n",
    "zdim = [1,2,3,4,5]\n",
    "\n",
    "for N_flows in flows:\n",
    "    for Z_DIM in zdim:\n",
    "        model = VAE_NF(N_FLOWS, Z_DIM).cuda()\n",
    "        optimizer = optim.Adam(model.parameters(), lr=LR)\n",
    "        BEST_LOSS = 99999\n",
    "        LAST_SAVED = -1\n",
    "        PATIENCE_COUNT = 0\n",
    "        PATIENCE_LIMIT = 5\n",
    "        for epoch in range(1, N_EPOCHS):\n",
    "            print(\"Epoch {}:\".format(epoch))\n",
    "            train()\n",
    "            cur_loss = evaluate()\n",
    "\n",
    "            if cur_loss <= BEST_LOSS:\n",
    "                PATIENCE_COUNT = 0\n",
    "                BEST_LOSS = cur_loss\n",
    "                LAST_SAVED = epoch\n",
    "                print(\"Saving model!\")\n",
    "                if mode == 'ROC':\n",
    "                    torch.save(model.state_dict(),f\"/data/t3home000/spark/QUASAR/weights/bkg_vae_NF_planar_RND_22var_z{Z_DIM}_f{N_FLOWS}.h5\")\n",
    "                else:\n",
    "                    torch.save(model.state_dict(), f\"/data/t3home000/spark/QUASAR/weights/bkg_vae_NF_planar_PureBkg_22var_z{Z_DIM}_f{N_FLOWS}.h5\")\n",
    "            else:\n",
    "                PATIENCE_COUNT += 1\n",
    "                print(\"Not saving model! Last saved: {}\".format(LAST_SAVED))\n",
    "                if PATIENCE_COUNT > 3:\n",
    "                    print(\"Patience Limit Reached\")\n",
    "                    break \n",
    "                    \n",
    "        loss_bkg = get_loss(dt_PureBkg[bkg_idx])\n",
    "        loss_sig = get_loss(dt_PureBkg[signal_idx])\n",
    "        np.save(f'NFLOWVAE_PlanarNEW_22var_z{Z_DIM}_f{N_flows}_sigloss.npy',loss_sig)\n",
    "        np.save(f'NFLOWVAE_PlanarNEW_22var_z{Z_DIM}_f{N_flows}_bkgloss.npy',loss_bkg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
