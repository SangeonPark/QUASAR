{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import tqdm\n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import torch \n",
    "import torch.nn as nn \n",
    "import torch.nn.functional as F \n",
    "import torch.optim as optim \n",
    "import torch.utils.data as utils\n",
    "import torch.nn.init as init\n",
    "from torch.autograd import Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "mode = 'ROC'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "f_rnd = pd.read_hdf(\"/data/t3home000/spark/LHCOlympics_previous/LHC-Olympics/Code/Nsubjettiness_mjj.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Mjj', 'Mj1', 'j1 tau1(b=.5)', 'j1 tau1(b=1)', 'j1 tau1(b=2)',\n",
       "       'j1 tau2(b=.5)', 'j1 tau2(b=1)', 'j1 tau2(b=2)', 'j1 tau3(b=.5)',\n",
       "       'j1 tau3(b=1)',\n",
       "       ...\n",
       "       'j2 tau15(b=2)', 'j2 n_trk', 'j2 pT1', 'j2 M_trim', 'j2 M_prun',\n",
       "       'j2 M_mmdt', 'j2 M_sdb1', 'j2 M_sdb2', 'j2 M_sdm1', 'isSignal'],\n",
       "      dtype='object', length=110)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f_rnd.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Mjj</th>\n",
       "      <th>Mj1</th>\n",
       "      <th>j1 tau1(b=.5)</th>\n",
       "      <th>j1 tau1(b=1)</th>\n",
       "      <th>j1 tau1(b=2)</th>\n",
       "      <th>j1 tau2(b=.5)</th>\n",
       "      <th>j1 tau2(b=1)</th>\n",
       "      <th>j1 tau2(b=2)</th>\n",
       "      <th>j1 tau3(b=.5)</th>\n",
       "      <th>j1 tau3(b=1)</th>\n",
       "      <th>...</th>\n",
       "      <th>j2 tau15(b=2)</th>\n",
       "      <th>j2 n_trk</th>\n",
       "      <th>j2 pT1</th>\n",
       "      <th>j2 M_trim</th>\n",
       "      <th>j2 M_prun</th>\n",
       "      <th>j2 M_mmdt</th>\n",
       "      <th>j2 M_sdb1</th>\n",
       "      <th>j2 M_sdb2</th>\n",
       "      <th>j2 M_sdm1</th>\n",
       "      <th>isSignal</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2577.571899</td>\n",
       "      <td>98.677270</td>\n",
       "      <td>0.053375</td>\n",
       "      <td>0.022677</td>\n",
       "      <td>0.009253</td>\n",
       "      <td>0.042518</td>\n",
       "      <td>0.011994</td>\n",
       "      <td>0.002307</td>\n",
       "      <td>0.038869</td>\n",
       "      <td>0.009455</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000051</td>\n",
       "      <td>128.0</td>\n",
       "      <td>1282.286017</td>\n",
       "      <td>42.162664</td>\n",
       "      <td>18.466533</td>\n",
       "      <td>18.466533</td>\n",
       "      <td>31.845136</td>\n",
       "      <td>42.162664</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3807.507389</td>\n",
       "      <td>584.595432</td>\n",
       "      <td>0.670141</td>\n",
       "      <td>0.490678</td>\n",
       "      <td>0.275638</td>\n",
       "      <td>0.331875</td>\n",
       "      <td>0.169591</td>\n",
       "      <td>0.060717</td>\n",
       "      <td>0.231046</td>\n",
       "      <td>0.078599</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001876</td>\n",
       "      <td>348.0</td>\n",
       "      <td>1306.137883</td>\n",
       "      <td>395.226881</td>\n",
       "      <td>393.309512</td>\n",
       "      <td>405.034096</td>\n",
       "      <td>405.034096</td>\n",
       "      <td>405.034096</td>\n",
       "      <td>405.034096</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1710.965414</td>\n",
       "      <td>159.597526</td>\n",
       "      <td>0.418784</td>\n",
       "      <td>0.241483</td>\n",
       "      <td>0.100078</td>\n",
       "      <td>0.343810</td>\n",
       "      <td>0.163651</td>\n",
       "      <td>0.051971</td>\n",
       "      <td>0.258793</td>\n",
       "      <td>0.113035</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001236</td>\n",
       "      <td>236.0</td>\n",
       "      <td>1072.462085</td>\n",
       "      <td>54.235070</td>\n",
       "      <td>41.967840</td>\n",
       "      <td>41.352112</td>\n",
       "      <td>51.721630</td>\n",
       "      <td>70.442364</td>\n",
       "      <td>-0.000003</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2603.379037</td>\n",
       "      <td>515.237299</td>\n",
       "      <td>0.483659</td>\n",
       "      <td>0.435741</td>\n",
       "      <td>0.230891</td>\n",
       "      <td>0.141166</td>\n",
       "      <td>0.039669</td>\n",
       "      <td>0.008714</td>\n",
       "      <td>0.114992</td>\n",
       "      <td>0.031118</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001400</td>\n",
       "      <td>352.0</td>\n",
       "      <td>1217.031950</td>\n",
       "      <td>81.842001</td>\n",
       "      <td>60.307703</td>\n",
       "      <td>60.307703</td>\n",
       "      <td>72.423677</td>\n",
       "      <td>84.480859</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3294.162200</td>\n",
       "      <td>142.420213</td>\n",
       "      <td>0.203619</td>\n",
       "      <td>0.087964</td>\n",
       "      <td>0.026577</td>\n",
       "      <td>0.149224</td>\n",
       "      <td>0.044661</td>\n",
       "      <td>0.006325</td>\n",
       "      <td>0.091160</td>\n",
       "      <td>0.023344</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000491</td>\n",
       "      <td>204.0</td>\n",
       "      <td>1205.343324</td>\n",
       "      <td>103.456059</td>\n",
       "      <td>99.817788</td>\n",
       "      <td>103.456059</td>\n",
       "      <td>103.456059</td>\n",
       "      <td>103.456059</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 110 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           Mjj         Mj1  j1 tau1(b=.5)  j1 tau1(b=1)  j1 tau1(b=2)  \\\n",
       "0  2577.571899   98.677270       0.053375      0.022677      0.009253   \n",
       "1  3807.507389  584.595432       0.670141      0.490678      0.275638   \n",
       "2  1710.965414  159.597526       0.418784      0.241483      0.100078   \n",
       "3  2603.379037  515.237299       0.483659      0.435741      0.230891   \n",
       "4  3294.162200  142.420213       0.203619      0.087964      0.026577   \n",
       "\n",
       "   j1 tau2(b=.5)  j1 tau2(b=1)  j1 tau2(b=2)  j1 tau3(b=.5)  j1 tau3(b=1)  \\\n",
       "0       0.042518      0.011994      0.002307       0.038869      0.009455   \n",
       "1       0.331875      0.169591      0.060717       0.231046      0.078599   \n",
       "2       0.343810      0.163651      0.051971       0.258793      0.113035   \n",
       "3       0.141166      0.039669      0.008714       0.114992      0.031118   \n",
       "4       0.149224      0.044661      0.006325       0.091160      0.023344   \n",
       "\n",
       "   ...  j2 tau15(b=2)  j2 n_trk       j2 pT1   j2 M_trim   j2 M_prun  \\\n",
       "0  ...       0.000051     128.0  1282.286017   42.162664   18.466533   \n",
       "1  ...       0.001876     348.0  1306.137883  395.226881  393.309512   \n",
       "2  ...       0.001236     236.0  1072.462085   54.235070   41.967840   \n",
       "3  ...       0.001400     352.0  1217.031950   81.842001   60.307703   \n",
       "4  ...       0.000491     204.0  1205.343324  103.456059   99.817788   \n",
       "\n",
       "    j2 M_mmdt   j2 M_sdb1   j2 M_sdb2   j2 M_sdm1  isSignal  \n",
       "0   18.466533   31.845136   42.162664    0.000000       0.0  \n",
       "1  405.034096  405.034096  405.034096  405.034096       0.0  \n",
       "2   41.352112   51.721630   70.442364   -0.000003       0.0  \n",
       "3   60.307703   72.423677   84.480859    0.000003       0.0  \n",
       "4  103.456059  103.456059  103.456059    0.000008       1.0  \n",
       "\n",
       "[5 rows x 110 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f_rnd.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "if mode == 'ROC':\n",
    "    dt = f_rnd.values\n",
    "else:\n",
    "    dt_PureBkg = f_PureBkg.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_list = [0,1,2,3,4,5,7,8,9,10,11,12]\n",
    "for i in index_list:\n",
    "    dt[:,i] = (dt[:,i]-np.mean(dt[:,i]))/np.std(dt[:,i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-9.76387849e-01,  1.92399512e-01,  6.41817483e-01, ...,\n",
       "         1.28228602e+03,  2.57757190e+03,  0.00000000e+00],\n",
       "       [ 2.56368470e+00, -7.40919608e-01, -1.86301047e+00, ...,\n",
       "         1.30613788e+03,  3.80750739e+03,  0.00000000e+00],\n",
       "       [-5.32563884e-01,  9.50088429e-01, -1.10614099e-01, ...,\n",
       "         1.07246208e+03,  1.71096541e+03,  0.00000000e+00],\n",
       "       ...,\n",
       "       [-1.14348172e+00,  7.85252036e-01,  1.12078063e-01, ...,\n",
       "         1.41629773e+03,  3.23296780e+03,  0.00000000e+00],\n",
       "       [-7.63183147e-01, -5.63390513e-02, -6.01315795e-01, ...,\n",
       "         1.13146135e+03,  3.60117240e+03,  0.00000000e+00],\n",
       "       [-1.02491235e+00, -1.27034111e-01, -8.10810555e-01, ...,\n",
       "         1.07347082e+03,  2.49024909e+03,  0.00000000e+00]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = dt[:,15]\n",
    "bkg_idx = np.where(idx==0)[0]\n",
    "signal_idx = np.where(idx==1)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[      0       1       2 ... 1099997 1099998 1099999]\n"
     ]
    }
   ],
   "source": [
    "print(bkg_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000000, 16)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt[bkg_idx].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_PureBkg = torch.tensor(dt[bkg_idx])\n",
    "total_PureBkg_train_x_1 = total_PureBkg.t()[0:6].t()\n",
    "total_PureBkg_train_x_3 = total_PureBkg.t()[7:13].t()\n",
    "total_PureBkg_selection = torch.cat((total_PureBkg_train_x_1,total_PureBkg_train_x_3),dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1000000, 12])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_PureBkg_selection.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set, val_set = torch.utils.data.random_split(total_PureBkg_selection, [800000, 200000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(train_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "bs = 256\n",
    "bkgAE_train_iterator = utils.DataLoader(total_PureBkg_selection, batch_size=bs, shuffle=True)\n",
    "bkgAE_test_iterator = utils.DataLoader(total_PureBkg_selection, batch_size=bs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    ''' This the encoder part of VAE\n",
    "\n",
    "    '''\n",
    "    def __init__(self, z_dim):\n",
    "        '''\n",
    "        Args:\n",
    "            input_dim: A integer indicating the size of input (in case of MNIST 28 * 28).\n",
    "            hidden_dim: A integer indicating the size of hidden dimension.\n",
    "            z_dim: A integer indicating the latent dimension.\n",
    "        '''\n",
    "        super().__init__()\n",
    "\n",
    "        self.linear1 = nn.Linear(12, 48)\n",
    "        self.linear2 = nn.Linear(48, 30)\n",
    "        self.linear3 = nn.Linear(30, 20)\n",
    "        self.linear4 = nn.Linear(20, 10)\n",
    "        self.linear5 = nn.Linear(10, 6)\n",
    "        hidden_dim = 6\n",
    "        self.mu = nn.Linear(hidden_dim, z_dim)\n",
    "        self.var = nn.Linear(hidden_dim, z_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x is of shape [batch_size, input_dim]\n",
    "        x = F.leaky_relu(self.linear1(x))\n",
    "        x = F.leaky_relu(self.linear2(x))\n",
    "        x = F.leaky_relu(self.linear3(x))\n",
    "        x = F.leaky_relu(self.linear4(x))\n",
    "        x = F.leaky_relu(self.linear5(x))\n",
    "\n",
    "        #hidden = F.relu(self.linear(x))\n",
    "        # hidden is of shape [batch_size, hidden_dim]\n",
    "        \n",
    "        z_mu = self.mu(x)\n",
    "        # z_mu is of shape [batch_size, latent_dim]\n",
    "        z_var = self.var(x)\n",
    "        # z_var is of shape [batch_size, latent_dim]\n",
    "\n",
    "        return z_mu, z_var\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "    ''' This the decoder part of VAE\n",
    "\n",
    "    '''\n",
    "    def __init__(self, z_dim):\n",
    "        '''\n",
    "        Args:\n",
    "            z_dim: A integer indicating the latent size.\n",
    "            hidden_dim: A integer indicating the size of hidden dimension.\n",
    "            output_dim: A integer indicating the output dimension (in case of MNIST it is 28 * 28)\n",
    "        '''\n",
    "        super().__init__()\n",
    "\n",
    "        self.linear1 = nn.Linear(z_dim, 6)\n",
    "        self.linear2 = nn.Linear(6, 10)\n",
    "        self.linear3 = nn.Linear(10, 20)\n",
    "        self.linear4 = nn.Linear(20, 30)\n",
    "        self.linear5 = nn.Linear(30, 48)\n",
    "        self.out = nn.Linear(48, 12)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x is of shape [batch_size, latent_dim]\n",
    "        x = F.leaky_relu(self.linear1(x))\n",
    "        x = F.leaky_relu(self.linear2(x))\n",
    "        x = F.leaky_relu(self.linear3(x))\n",
    "        x = F.leaky_relu(self.linear4(x))\n",
    "        x = F.leaky_relu(self.linear5(x))\n",
    "\n",
    "        #hidden = F.relu(self.linear(x))\n",
    "        # hidden is of shape [batch_size, hidden_dim]\n",
    "\n",
    "        predicted = torch.sigmoid(self.out(x))\n",
    "        # predicted is of shape [batch_size, output_dim]\n",
    "\n",
    "        return predicted\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VAE(nn.Module):\n",
    "    ''' This the VAE, which takes a encoder and decoder.\n",
    "\n",
    "    '''\n",
    "    def __init__(self, enc, dec):\n",
    "        super().__init__()\n",
    "\n",
    "        self.enc = enc\n",
    "        self.dec = dec\n",
    "\n",
    "    def forward(self, x):\n",
    "        # encode\n",
    "        z_mu, z_var = self.enc(x)\n",
    "\n",
    "        # sample from the distribution having latent parameters z_mu, z_var\n",
    "        # reparameterize\n",
    "        std = torch.exp(z_var / 2)\n",
    "        eps = torch.randn_like(std)\n",
    "        x_sample = eps.mul(std).add_(z_mu)\n",
    "\n",
    "        # decode\n",
    "        predicted = self.dec(x_sample)\n",
    "        return predicted, z_mu, z_var\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'GeForce RTX 2080 Ti'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "torch.cuda.get_device_name(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# encoder\n",
    "encoder = Encoder(3)\n",
    "\n",
    "# decoder\n",
    "decoder = Decoder(3)\n",
    "\n",
    "# vae\n",
    "model = VAE(encoder, decoder).to(device)\n",
    "\n",
    "# optimizer\n",
    "lr = 1e-4\n",
    "optimizer = optim.Adam(model.parameters(), lr=lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model)\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train():\n",
    "    # set the train mode\n",
    "    model.train()\n",
    "\n",
    "    # loss of the epoch\n",
    "    train_loss = 0\n",
    "\n",
    "    for i, x in enumerate(bkgAE_train_iterator):\n",
    "        # reshape the data into [batch_size, 784]\n",
    "        x = x.float().cuda()\n",
    "\n",
    "        # update the gradients to zero\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward pass\n",
    "        x_sample, z_mu, z_var = model(x)\n",
    "\n",
    "        # reconstruction loss\n",
    "        recon_loss = F.binary_cross_entropy(x_sample, x, size_average=False)\n",
    "\n",
    "        # kl divergence loss\n",
    "        kl_loss = 0.5 * torch.sum(torch.exp(z_var) + z_mu**2 - 1.0 - z_var)\n",
    "\n",
    "        # total loss\n",
    "        loss = recon_loss + kl_loss\n",
    "\n",
    "        # backward pass\n",
    "        loss.backward()\n",
    "        train_loss += loss.item()\n",
    "\n",
    "        # update the weights\n",
    "        optimizer.step()\n",
    "\n",
    "    return train_loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test():\n",
    "    # set the evaluation mode\n",
    "    model.eval()\n",
    "\n",
    "    # test loss for the data\n",
    "    test_loss = 0\n",
    "\n",
    "    # we don't need to track the gradients, since we are not updating the parameters during evaluation / testing\n",
    "    with torch.no_grad():\n",
    "        for i, x in enumerate(bkgAE_test_iterator):\n",
    "            # reshape the data\n",
    "            #x = x.view(-1, 28 * 28)\n",
    "            x = x.float().cuda()\n",
    "            # forward pass\n",
    "            x_sample, z_mu, z_var = model(x)\n",
    "\n",
    "            # reconstruction loss\n",
    "            recon_loss = F.binary_cross_entropy(x_sample, x, size_average=False)\n",
    "\n",
    "            # kl divergence loss\n",
    "            kl_loss = 0.5 * torch.sum(torch.exp(z_var) + z_mu**2 - 1.0 - z_var)\n",
    "\n",
    "            # total loss\n",
    "            loss = recon_loss + kl_loss\n",
    "            test_loss += loss.item()\n",
    "\n",
    "    return test_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_test_loss = float('inf')\n",
    "\n",
    "for e in range(10):\n",
    "\n",
    "    train_loss = train()\n",
    "    test_loss = test()\n",
    "\n",
    "    train_loss /= len(total_PureBkg_selection)\n",
    "    test_loss /= len(total_PureBkg_selection)\n",
    "\n",
    "    print(f'Epoch {e}, Train Loss: {train_loss:.2f}, Test Loss: {test_loss:.2f}')\n",
    "\n",
    "    if best_test_loss > test_loss:\n",
    "        best_test_loss = test_loss\n",
    "        patience_counter = 1\n",
    "        print(\"Saving model!\")\n",
    "        if mode == 'ROC':\n",
    "            torch.save(model.state_dict(),\"/data/t3home000/spark/QUASAR/weights/bkg_vae_Vanilla_RND.h5\")\n",
    "        else:\n",
    "            torch.save(model.state_dict(), \"/data/t3home000/spark/QUASAR/weights/bkg_vae_Vanilla_PureBkg.h5\")\n",
    "    else:\n",
    "        patience_counter += 1\n",
    "        print(\"Not saving model!\")\n",
    "\n",
    "    if patience_counter > 3:\n",
    "        print(\"Patience Limit Reached\")\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(mode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_state_dict(torch.load(\"/data/t3home000/spark/QUASAR/weights/bkg_vae_Vanilla_RND.h5\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_loss(dt, index_list):\n",
    "    print(dt.shape)\n",
    "    \n",
    "    #for i in index_list:\n",
    "    #    print(i)\n",
    "    #    dt[:,i] = (dt[:,i]-np.mean(dt[:,i]))/np.std(dt[:,i])\n",
    "  \n",
    "    \n",
    "    total_in = torch.tensor(dt)\n",
    "    total_in_train_x_1 = total_in.t()[0:6].t()\n",
    "    total_in_train_x_3 = total_in.t()[7:13].t()\n",
    "    total_in_selection = torch.cat((total_in_train_x_1,total_in_train_x_3),dim=1)\n",
    "    z_mu, z_var  = model.enc(total_in_selection.float().cuda())\n",
    "    std = torch.exp(z_var / 2)\n",
    "    eps = torch.randn_like(std)\n",
    "    x_sample = eps.mul(std).add_(z_mu)\n",
    "    decoded_bkg = model.dec(x_sample)\n",
    "    loss_bkg = torch.mean((decoded_bkg-total_in_selection.float().cuda())**2,dim=1).data.cpu().numpy()\n",
    "\n",
    "\n",
    "    \n",
    "    #with torch.no_grad():\n",
    "        # reconstruction loss\n",
    "        #x_sample, z_mu, z_var = model(total_in_selection.float().cuda())\n",
    "        #recon_loss = F.binary_cross_entropy(x_sample, total_in_selection.float().cuda(), size_average=False, reduce=None)\n",
    "        \n",
    "\n",
    "        # kl divergence loss\n",
    "        #kl_loss = 0.5 * torch.sum(torch.exp(z_var) + z_mu**2 - 1.0 - z_var)\n",
    "\n",
    "        # total loss\n",
    "        #loss = recon_loss + kl_loss\n",
    "        #loss = torch.mean((model(total_in_selection.float().cuda())[0]- total_in_selection.float().cuda())**2,dim=1).data.cpu().numpy()\n",
    "    \n",
    "    return loss_bkg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_bkg = torch.tensor(dt[bkg_idx])\n",
    "data_signal = torch.tensor(dt[signal_idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1000000, 16])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_bkg.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train_x_1 = data_bkg.t()[0:6].t()\n",
    "data_train_x_2 = data_bkg.t()[7:13].t()\n",
    "data_test_bkg = torch.cat((data_train_x_1,data_train_x_2),dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train_x_1 = data_signal.t()[0:6].t()\n",
    "data_train_x_2 = data_signal.t()[7:13].t()\n",
    "data_test_signal = torch.cat((data_train_x_1,data_train_x_2),dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "z_mu, z_var  = model.enc(data_test_bkg.float().cuda())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "std = torch.exp(z_var / 2)\n",
    "eps = torch.randn_like(std)\n",
    "x_sample = eps.mul(std).add_(z_mu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoded_bkg = model.dec(x_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_bkg = torch.mean((decoded_bkg-data_test_bkg.float().cuda())**2,dim=1).data.cpu().numpy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "z_mu2, z_var2  = model.enc(data_test_signal.float().cuda())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "std2 = torch.exp(z_var2 / 2)\n",
    "eps2 = torch.randn_like(std2)\n",
    "x_sample2 = eps2.mul(std2).add_(z_mu2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoded_sig = model.dec(x_sample2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_sig = torch.mean((decoded_sig-data_test_signal.float().cuda())**2,dim=1).data.cpu().numpy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.90558827, 2.4635067 , 0.61185807, ..., 0.46641356, 0.66532624,\n",
       "       1.351981  ], dtype=float32)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss_bkg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0.000e+00, 3.000e+00, 1.300e+01, 5.800e+01, 1.720e+02, 3.140e+02,\n",
       "        5.100e+02, 7.160e+02, 9.570e+02, 1.217e+03, 1.463e+03, 1.738e+03,\n",
       "        1.917e+03, 2.082e+03, 2.458e+03, 2.751e+03, 2.811e+03, 3.196e+03,\n",
       "        3.245e+03, 3.514e+03, 3.582e+03, 3.716e+03, 3.779e+03, 3.769e+03,\n",
       "        3.793e+03, 3.751e+03, 3.630e+03, 3.522e+03, 3.419e+03, 3.268e+03,\n",
       "        3.030e+03, 2.820e+03, 2.679e+03, 2.430e+03, 2.319e+03, 2.022e+03,\n",
       "        1.816e+03, 1.534e+03, 1.530e+03, 1.366e+03, 1.244e+03, 1.105e+03,\n",
       "        1.000e+03, 9.010e+02, 7.540e+02, 7.140e+02, 5.800e+02, 6.230e+02,\n",
       "        5.220e+02, 4.900e+02, 4.200e+02, 4.090e+02, 3.410e+02, 3.400e+02,\n",
       "        3.000e+02, 2.830e+02, 2.220e+02, 2.030e+02, 1.890e+02, 2.030e+02,\n",
       "        1.500e+02, 1.370e+02, 1.270e+02, 1.190e+02, 1.120e+02, 1.080e+02,\n",
       "        1.030e+02, 1.010e+02, 8.600e+01, 7.600e+01, 5.400e+01, 7.600e+01,\n",
       "        6.500e+01, 6.100e+01, 4.100e+01, 5.900e+01, 4.300e+01, 4.500e+01,\n",
       "        5.500e+01, 3.900e+01, 3.000e+01, 3.200e+01, 2.600e+01, 2.400e+01,\n",
       "        3.000e+01, 2.900e+01, 2.000e+01, 2.200e+01, 2.600e+01, 2.200e+01,\n",
       "        1.500e+01, 2.200e+01, 1.100e+01, 1.700e+01, 1.400e+01, 1.200e+01,\n",
       "        1.500e+01, 8.000e+00, 1.000e+01]),\n",
       " array([0.        , 0.05050505, 0.1010101 , 0.15151515, 0.2020202 ,\n",
       "        0.25252525, 0.3030303 , 0.35353535, 0.4040404 , 0.45454545,\n",
       "        0.50505051, 0.55555556, 0.60606061, 0.65656566, 0.70707071,\n",
       "        0.75757576, 0.80808081, 0.85858586, 0.90909091, 0.95959596,\n",
       "        1.01010101, 1.06060606, 1.11111111, 1.16161616, 1.21212121,\n",
       "        1.26262626, 1.31313131, 1.36363636, 1.41414141, 1.46464646,\n",
       "        1.51515152, 1.56565657, 1.61616162, 1.66666667, 1.71717172,\n",
       "        1.76767677, 1.81818182, 1.86868687, 1.91919192, 1.96969697,\n",
       "        2.02020202, 2.07070707, 2.12121212, 2.17171717, 2.22222222,\n",
       "        2.27272727, 2.32323232, 2.37373737, 2.42424242, 2.47474747,\n",
       "        2.52525253, 2.57575758, 2.62626263, 2.67676768, 2.72727273,\n",
       "        2.77777778, 2.82828283, 2.87878788, 2.92929293, 2.97979798,\n",
       "        3.03030303, 3.08080808, 3.13131313, 3.18181818, 3.23232323,\n",
       "        3.28282828, 3.33333333, 3.38383838, 3.43434343, 3.48484848,\n",
       "        3.53535354, 3.58585859, 3.63636364, 3.68686869, 3.73737374,\n",
       "        3.78787879, 3.83838384, 3.88888889, 3.93939394, 3.98989899,\n",
       "        4.04040404, 4.09090909, 4.14141414, 4.19191919, 4.24242424,\n",
       "        4.29292929, 4.34343434, 4.39393939, 4.44444444, 4.49494949,\n",
       "        4.54545455, 4.5959596 , 4.64646465, 4.6969697 , 4.74747475,\n",
       "        4.7979798 , 4.84848485, 4.8989899 , 4.94949495, 5.        ]),\n",
       " <a list of 99 Patch objects>)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "bins = np.linspace(0,5,100)\n",
    "plt.hist(loss_bkg,bins=bins,alpha=0.3,color='b',label='bkg')\n",
    "plt.hist(loss_sig,bins=bins,alpha=0.3,color='r',label='sig')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = pd.read_hdf(\"/data/t3home000/spark/LHCOlympics_previous/LHC-Olympics/Code/Nsubjettiness_mjj.h5\")\n",
    "dt = f.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = dt[:,15]\n",
    "bkg_idx = np.where(idx==0)[0]\n",
    "signal_idx = np.where(idx==1)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000000, 16)\n",
      "(100000, 16)\n"
     ]
    }
   ],
   "source": [
    "loss_bkg = get_loss(dt[bkg_idx],[0,1,2,3,4,5,7,8,9,10,11,12])\n",
    "loss_sig = get_loss(dt[signal_idx],[0,1,2,3,4,5,7,8,9,10,11,12])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.rcParams[\"figure.figsize\"] = (10,10)\n",
    "bins = np.linspace(0,5,100)\n",
    "plt.hist(loss_bkg,bins=bins,alpha=0.3,color='b',label='bkg')\n",
    "plt.hist(loss_sig,bins=bins,alpha=0.3,color='r',label='sig')\n",
    "plt.xlabel(r'Autoencoder Loss')\n",
    "plt.ylabel('Count')\n",
    "plt.legend(loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ROC\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tpr_fpr(sigloss,bkgloss,aetype='bkg'):\n",
    "    bins = np.linspace(0,50,1001)\n",
    "    tpr = []\n",
    "    fpr = []\n",
    "    for cut in bins:\n",
    "        if aetype == 'sig':\n",
    "            tpr.append(np.where(sigloss<cut)[0].shape[0]/len(sigloss))\n",
    "            fpr.append(np.where(bkgloss<cut)[0].shape[0]/len(bkgloss))\n",
    "        if aetype == 'bkg':\n",
    "            tpr.append(np.where(sigloss>cut)[0].shape[0]/len(sigloss))\n",
    "            fpr.append(np.where(bkgloss>cut)[0].shape[0]/len(bkgloss))\n",
    "    return tpr,fpr  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PRECISION - RECALL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_precision_recall(sigloss,bkgloss,aetype='bkg'):\n",
    "    bins = np.linspace(0,100,1001)\n",
    "    tpr = []\n",
    "    fpr = []\n",
    "    precision = []\n",
    "    for cut in bins:\n",
    "        if aetype == 'sig':\n",
    "            tpr.append(np.where(sigloss<cut)[0].shape[0]/len(sigloss))\n",
    "            precision.append((np.where(sigloss<cut)[0].shape[0])/(np.where(bkgloss<cut)[0].shape[0]+np.where(sigloss<cut)[0].shape[0]))\n",
    "            \n",
    "        if aetype == 'bkg':\n",
    "            tpr.append(np.where(sigloss>cut)[0].shape[0]/len(sigloss))\n",
    "            precision.append((np.where(sigloss>cut)[0].shape[0])/(np.where(bkgloss>cut)[0].shape[0]+np.where(sigloss>cut)[0].shape[0]))\n",
    "    return precision,tpr      "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
