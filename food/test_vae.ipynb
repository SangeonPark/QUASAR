{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "boolean-notice",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Packages for training the model and working with the dataset.\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import json\n",
    "\n",
    "# Utility/helper packages.\n",
    "import platform\n",
    "import time\n",
    "import pathlib\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "royal-drive",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/device:CPU:0', '/device:GPU:0']\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.python.client import device_lib\n",
    "\n",
    "def get_available_devices():\n",
    "    local_device_protos = device_lib.list_local_devices()\n",
    "    return [x.name for x in local_device_protos]\n",
    "\n",
    "print(get_available_devices())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "correct-moisture",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./tmp/datasets/recipes_raw.zip\n"
     ]
    }
   ],
   "source": [
    "CACHE_DIR = './tmp'\n",
    "pathlib.Path(CACHE_DIR).mkdir(exist_ok=True)\n",
    "\n",
    "dataset_file_name = 'recipes_raw.zip'\n",
    "dataset_file_origin = 'https://storage.googleapis.com/recipe-box/recipes_raw.zip'\n",
    "\n",
    "dataset_file_path = tf.keras.utils.get_file(\n",
    "    fname=dataset_file_name,\n",
    "    origin=dataset_file_origin,\n",
    "    cache_dir=CACHE_DIR,\n",
    "    extract=True,\n",
    "    archive_format='zip'\n",
    ")\n",
    "\n",
    "print(dataset_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "consolidated-circular",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset(silent=True):\n",
    "    # List of dataset files we want to merge.\n",
    "    dataset_file_names = [\n",
    "        'recipes_raw_nosource_ar.json',\n",
    "        'recipes_raw_nosource_epi.json',\n",
    "        'recipes_raw_nosource_fn.json',\n",
    "    ]\n",
    "    \n",
    "    dataset = []\n",
    "\n",
    "    for dataset_file_name in dataset_file_names:\n",
    "        dataset_file_path = f'{CACHE_DIR}/datasets/{dataset_file_name}'\n",
    "\n",
    "        with open(dataset_file_path) as dataset_file:\n",
    "            json_data_dict = json.load(dataset_file)\n",
    "            json_data_list = list(json_data_dict.values())\n",
    "            dict_keys = [key for key in json_data_list[0]]\n",
    "            dict_keys.sort()\n",
    "            dataset += json_data_list\n",
    "\n",
    "            # This code block outputs the summary for each dataset.\n",
    "            if silent == False:\n",
    "                print(dataset_file_path)\n",
    "                print('===========================================')\n",
    "                print('Number of examples: ', len(json_data_list), '\\n')\n",
    "                print('Example object keys:\\n', dict_keys, '\\n')\n",
    "                print('Example object:\\n', json_data_list[0], '\\n')\n",
    "                print('Required keys:\\n')\n",
    "                print('  title: ', json_data_list[0]['title'], '\\n')\n",
    "                print('  ingredients: ', json_data_list[0]['ingredients'], '\\n')\n",
    "                print('  instructions: ', json_data_list[0]['instructions'])\n",
    "                print('\\n\\n')\n",
    "\n",
    "    return dataset  \n",
    "\n",
    "dataset_raw = load_dataset() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "julian-synthesis",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stringified dataset size:  122938\n",
      "Dataset size BEFORE filtering:  122938\n",
      "Dataset size AFTER filtering:  103216\n"
     ]
    }
   ],
   "source": [
    "def recipe_validate_required_fields(recipe):\n",
    "    required_keys = ['title', 'ingredients', 'instructions']\n",
    "    \n",
    "    if not recipe:\n",
    "        return False\n",
    "    \n",
    "    for required_key in required_keys:\n",
    "        if not recipe[required_key]:\n",
    "            return False\n",
    "        \n",
    "        if type(recipe[required_key]) == list and len(recipe[required_key]) == 0:\n",
    "            return False\n",
    "    \n",
    "    return True\n",
    "\n",
    "STOP_WORD_TITLE = 'üìó '\n",
    "STOP_WORD_INGREDIENTS = '\\nü•ï\\n\\n'\n",
    "STOP_WORD_INSTRUCTIONS = '\\nüìù\\n\\n'\n",
    "\n",
    "def recipe_to_string(recipe):\n",
    "    # This string is presented as a part of recipes so we need to clean it up.\n",
    "    noize_string = 'ADVERTISEMENT'\n",
    "    \n",
    "    title = (recipe['title']).lower()\n",
    "    ingredients = recipe['ingredients']\n",
    "    instructions = recipe['instructions'].split('\\n')\n",
    "    \n",
    "    ingredients_string = ''\n",
    "    for ingredient in ingredients:\n",
    "        ingredient = ingredient.replace(noize_string, '')\n",
    "        if ingredient:\n",
    "            ingredients_string += f' {ingredient.lower()}\\n'\n",
    "       \n",
    "    return f'{ingredients_string}'\n",
    "\n",
    "dataset_raw = load_dataset() \n",
    "dataset_validated = [recipe for recipe in dataset_raw if recipe_validate_required_fields(recipe)]\n",
    "dataset_stringified = [recipe_to_string(recipe) for recipe in dataset_validated]\n",
    "print('Stringified dataset size: ', len(dataset_stringified))\n",
    "\n",
    "MAX_RECIPE_LENGTH = 500\n",
    "def filter_recipes_by_length(recipe_test):\n",
    "    return len(recipe_test) <= MAX_RECIPE_LENGTH \n",
    "\n",
    "dataset_filtered = [recipe_text for recipe_text in dataset_stringified if filter_recipes_by_length(recipe_text)]\n",
    "\n",
    "print('Dataset size BEFORE filtering: ', len(dataset_stringified))\n",
    "print('Dataset size AFTER filtering: ', len(dataset_filtered))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "miniature-tamil",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VOCABULARY_SIZE:  12743\n"
     ]
    }
   ],
   "source": [
    "STOP_SIGN = '‚ê£'\n",
    "\n",
    "tokenizer = tf.keras.preprocessing.text.Tokenizer(\n",
    "    char_level=False,\n",
    "    filters='\\'''!\"#$%&()*+,-./:;<=>?@[\\\\]^_`{|}~\\t\\n¬Æ',\n",
    "    lower=True,\n",
    "    split=' ',\n",
    "    oov_token=None,\n",
    ")\n",
    "\n",
    "# Stop word is not a part of recipes, but tokenizer must know about it as well.\n",
    "tokenizer.fit_on_texts([STOP_SIGN])\n",
    "tokenizer.fit_on_texts(dataset_filtered)\n",
    "tokenizer.get_config()\n",
    "VOCABULARY_SIZE = len(tokenizer.word_counts) + 1\n",
    "print('VOCABULARY_SIZE: ', VOCABULARY_SIZE)\n",
    "#print(tokenizer.word_counts.items())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "commercial-viking",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset size BEFORE filtering:  122938\n",
      "Dataset size AFTER filtering:  103216\n"
     ]
    }
   ],
   "source": [
    "MAX_RECIPE_LENGTH = 500\n",
    "def filter_recipes_by_length(recipe_test):\n",
    "    return len(recipe_test) <= MAX_RECIPE_LENGTH \n",
    "\n",
    "dataset_filtered = [recipe_text for recipe_text in dataset_stringified if filter_recipes_by_length(recipe_text)]\n",
    "\n",
    "print('Dataset size BEFORE filtering: ', len(dataset_stringified))\n",
    "print('Dataset size AFTER filtering: ', len(dataset_filtered))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "legal-bonus",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vectorized dataset size 103216\n",
      "[4, 209, 160, 61, 226, 246, 2, 7, 20, 2] ...\n",
      "4 skinless boneless chicken breast halves 2 tablespoons butter 2 10 75 ounce cans condensed cream of chicken soup 1 onion finely diced 2 10 ounce packages refrigerated biscuit dough torn into pieces\n",
      "Recipe #1 length: 33\n",
      "Recipe #2 length: 29\n",
      "Recipe #3 length: 51\n",
      "Recipe #4 length: 45\n",
      "Recipe #5 length: 72\n",
      "Recipe #6 length: 32\n",
      "Recipe #7 length: 44\n",
      "Recipe #8 length: 28\n",
      "Recipe #9 length: 54\n",
      "Recipe #10 length: 44\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX0AAAD5CAYAAADLL+UrAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8rg+JYAAAACXBIWXMAAAsTAAALEwEAmpwYAAASTklEQVR4nO3df6zd9X3f8eerJiUkHQoMw1zbml3J6wpICeXK85ap6ko33FDV/EPlShnWZskSYgudKnV2+8fUPywxaapapIFkkRSzZqFWmg4rDU2Zu6itxHAuTVYwxMMLCN/ZxbdJs9L+QYrz3h/ng3pkH9977rV9rs/5PB/S0ff7fZ/v95zPR7Zf9+PP98dNVSFJ6sP3rXUDJEmTY+hLUkcMfUnqiKEvSR0x9CWpI4a+JHXkunF2SvIR4EngTqCAfw2cBH4L2AK8CfxsVf1F2/8AsBc4D3yqqr7c6ncDTwE3AF8CHqllrhm95ZZbasuWLSvqlCT17qWXXvrzqlp/YT3jXKef5DDwR1X1ZJLvBz4E/BLw7ap6NMl+4Kaq+vdJbgc+B2wHfhD478A/qKrzSY4DjwD/k0HoP1ZVzy313XNzczU/P7+izkpS75K8VFVzF9aXnd5JciPwY8CnAarqu1X1HWAXcLjtdhi4v63vAp6pqner6g3gFLA9yQbgxqp6oY3unx46RpI0AePM6f8QsAj8RpKvJXkyyYeB26rqLEBb3tr23wicHjp+odU2tvUL65KkCRkn9K8DfhR4oqruAv4a2L/E/hlRqyXqF39Asi/JfJL5xcXFMZooSRrHOKG/ACxU1Ytt+/MMfgi83aZsaMtzQ/tvHjp+E3Cm1TeNqF+kqg5V1VxVza1ff9F5CEnSKi0b+lX1Z8DpJD/cSvcArwJHgT2ttgd4tq0fBXYnuT7JVmAbcLxNAb2TZEeSAA8OHSNJmoCxLtkE/i3w2XblzjeBf8XgB8aRJHuBt4AHAKrqRJIjDH4wvAc8XFXn2+c8xN9esvlce0mSJmSsSzbXkpdsStLKrfqSTUnS7DD0Jakj487pS2tuy/7fHVl/89H7JtwSaXo50pekjhj6ktQRQ1+SOmLoS1JHDH1J6oihL0kdMfQlqSOGviR1xJuzdEV445Q0HRzpS1JHDH1J6oihL0kdMfQlqSOGviR1xNCXpI4Y+pLUEUNfkjpi6EtSR7wjV2q8q1g9cKQvSR0x9CWpI4a+JHXE0Jekjhj6ktSRsUI/yZtJXk7y9STzrXZzkueTvN6WNw3tfyDJqSQnk9w7VL+7fc6pJI8lyZXvkiTpUlYy0v9nVfWxqppr2/uBY1W1DTjWtklyO7AbuAPYCTyeZF075glgH7CtvXZefhckSeO6nOmdXcDhtn4YuH+o/kxVvVtVbwCngO1JNgA3VtULVVXA00PHSJImYNzQL+D3k7yUZF+r3VZVZwHa8tZW3wicHjp2odU2tvUL6xdJsi/JfJL5xcXFMZsoSVrOuHfkfryqziS5FXg+yTeW2HfUPH0tUb+4WHUIOAQwNzc3ch9J0sqNNdKvqjNteQ74HWA78HabsqEtz7XdF4DNQ4dvAs60+qYRdUnShCwb+kk+nOTvvL8O/AvgFeAosKfttgd4tq0fBXYnuT7JVgYnbI+3KaB3kuxoV+08OHSMJGkCxpneuQ34nXZ15XXAf62q30vyVeBIkr3AW8ADAFV1IskR4FXgPeDhqjrfPush4CngBuC59pIkTciyoV9V3wQ+OqL+LeCeSxxzEDg4oj4P3LnyZkqSrgTvyJWkjhj6ktQRQ1+SOmLoS1JHDH1J6oihL0kdMfQlqSOGviR1xNCXpI4Y+pLUEUNfkjpi6EtSRwx9SerIuL85S9KYtuz/3ZH1Nx+9b8ItkS7mSF+SOmLoS1JHDH1J6oihL0kd8URuJzy5KAkc6UtSVwx9SeqIoS9JHTH0Jakjhr4kdcTQl6SOGPqS1BFDX5I6MnboJ1mX5GtJvti2b07yfJLX2/KmoX0PJDmV5GSSe4fqdyd5ub33WJJc2e5IkpaykpH+I8BrQ9v7gWNVtQ041rZJcjuwG7gD2Ak8nmRdO+YJYB+wrb12XlbrJUkrMlboJ9kE3Ac8OVTeBRxu64eB+4fqz1TVu1X1BnAK2J5kA3BjVb1QVQU8PXSMJGkCxh3p/xrwi8D3hmq3VdVZgLa8tdU3AqeH9ltotY1t/cL6RZLsSzKfZH5xcXHMJkqSlrNs6Cf5aeBcVb005meOmqevJeoXF6sOVdVcVc2tX79+zK+VJC1nnKdsfhz4mSSfAD4I3JjkN4G3k2yoqrNt6uZc238B2Dx0/CbgTKtvGlGXJE3IsiP9qjpQVZuqaguDE7R/UFWfBI4Ce9pue4Bn2/pRYHeS65NsZXDC9nibAnonyY521c6DQ8dIkibgcp6n/yhwJMle4C3gAYCqOpHkCPAq8B7wcFWdb8c8BDwF3AA8117qkM/3l9bGikK/qr4CfKWtfwu45xL7HQQOjqjPA3eutJGSpCvD35ylqef/GqTxGfq6qi4VyJLWhs/ekaSOONLXzHLaR7qYI31J6ogjfV1TPAcgXV2O9CWpI4a+JHXE6R11ZxamkDxJrdVypC9JHTH0Jakjhr4kdcQ5fa3ILMyHSz1zpC9JHTH0Jakjhr4kdcQ5fY3k3L00mxzpS1JHHOlLy/DuV80SR/qS1BFDX5I64vRO5zxhK/XFkb4kdcSRvrRK/i9J08iRviR1xNCXpI4sG/pJPpjkeJL/leREkl9p9ZuTPJ/k9ba8aeiYA0lOJTmZ5N6h+t1JXm7vPZYkV6dbkqRRxhnpvwv8RFV9FPgYsDPJDmA/cKyqtgHH2jZJbgd2A3cAO4HHk6xrn/UEsA/Y1l47r1xXJEnLWTb0a+Cv2uYH2quAXcDhVj8M3N/WdwHPVNW7VfUGcArYnmQDcGNVvVBVBTw9dIwkaQLGmtNPsi7J14FzwPNV9SJwW1WdBWjLW9vuG4HTQ4cvtNrGtn5hXZI0IWOFflWdr6qPAZsYjNrvXGL3UfP0tUT94g9I9iWZTzK/uLg4ThMlSWNY0dU7VfUd4CsM5uLfblM2tOW5ttsCsHnosE3AmVbfNKI+6nsOVdVcVc2tX79+JU2UJC1hnKt31if5SFu/AfhJ4BvAUWBP220P8GxbPwrsTnJ9kq0MTtgeb1NA7yTZ0a7aeXDoGEnSBIxzR+4G4HC7Auf7gCNV9cUkLwBHkuwF3gIeAKiqE0mOAK8C7wEPV9X59lkPAU8BNwDPtZckaUKWDf2q+lPgrhH1bwH3XOKYg8DBEfV5YKnzAZKkq8hn70gT4i9j0bXAxzBIUkcMfUnqiNM70hpz2keT5Ehfkjpi6EtSR5zekXQRp5xmlyN9SeqII/0Z4+9tlbQUR/qS1BFDX5I64vSOdI1yqk5XgyN9SeqIoS9JHTH0Jakjhr4kdcTQl6SOGPqS1BFDX5I64nX61wgfcCVpEgz9KeWNO5JWw+kdSeqII31phjhNqOU40pekjhj6ktQRp3ekDjjto/c50pekjiw70k+yGXga+HvA94BDVfXrSW4GfgvYArwJ/GxV/UU75gCwFzgPfKqqvtzqdwNPATcAXwIeqaq6sl2SNC4v/e3POCP994BfqKofAXYADye5HdgPHKuqbcCxtk17bzdwB7ATeDzJuvZZTwD7gG3ttfMK9kWStIxlQ7+qzlbVn7T1d4DXgI3ALuBw2+0wcH9b3wU8U1XvVtUbwClge5INwI1V9UIb3T89dIwkaQJWNKefZAtwF/AicFtVnYXBDwbg1rbbRuD00GELrbaxrV9YH/U9+5LMJ5lfXFxcSRMlSUsYO/ST/ADw28DPV9VfLrXriFotUb+4WHWoquaqam79+vXjNlGStIyxLtlM8gEGgf/ZqvpCK7+dZENVnW1TN+dafQHYPHT4JuBMq28aUdcSPNEm6UpadqSfJMCngdeq6leH3joK7Gnre4Bnh+q7k1yfZCuDE7bH2xTQO0l2tM98cOgYSdIEjDPS/zjwL4GXk3y91X4JeBQ4kmQv8BbwAEBVnUhyBHiVwZU/D1fV+XbcQ/ztJZvPtZckaUKWDf2q+mNGz8cD3HOJYw4CB0fU54E7V9JASdKV4x25ktQRQ1+SOmLoS1JHDH1J6oihL0kdMfQlqSOGviR1xNCXpI4Y+pLUEUNfkjpi6EtSR8Z6tLIkwaUf9f3mo/dNuCVaLUf6ktQRQ1+SOmLoS1JHDH1J6oihL0kdMfQlqSOGviR1xNCXpI4Y+pLUEe/IlXTZvFN3ejjSl6SOGPqS1BFDX5I64pz+BF1q3lOSJsWRviR1ZNnQT/KZJOeSvDJUuznJ80leb8ubht47kORUkpNJ7h2q353k5fbeY0ly5bsjSVrKOCP9p4CdF9T2A8eqahtwrG2T5HZgN3BHO+bxJOvaMU8A+4Bt7XXhZ0qSrrJlQ7+q/hD49gXlXcDhtn4YuH+o/kxVvVtVbwCngO1JNgA3VtULVVXA00PHSJImZLVz+rdV1VmAtry11TcCp4f2W2i1jW39wvpISfYlmU8yv7i4uMomSpIudKVP5I6ap68l6iNV1aGqmququfXr11+xxklS71Yb+m+3KRva8lyrLwCbh/bbBJxp9U0j6pKkCVpt6B8F9rT1PcCzQ/XdSa5PspXBCdvjbQronSQ72lU7Dw4dI0makGVvzkryOeDHgVuSLAD/AXgUOJJkL/AW8ABAVZ1IcgR4FXgPeLiqzrePeojBlUA3AM+1l6QZ5oPYrj3Lhn5V/dwl3rrnEvsfBA6OqM8Dd66odVPKO28lXau8I1eSOmLoS1JHfOCapIlzrn/tONKXpI4Y+pLUEUNfkjpi6EtSRwx9SeqIV+9cBm/CkjRtHOlLUkcMfUnqiNM7Y3AaR9KscKQvSR0x9CWpI4a+JHXE0Jekjhj6ktQRQ1+SOmLoS1JHDH1J6og3Z0m6Zvgbta4+R/qS1BFDX5I6YuhLUkec0x/ig9UkzTpDX9I1zxO8V87Ep3eS7ExyMsmpJPsn/f2S1LOJjvSTrAP+M/DPgQXgq0mOVtWrk2yH0ziSejXp6Z3twKmq+iZAkmeAXcBVCX3DXZptS/0bd+pntEmH/kbg9ND2AvCPJtwGSR1Y6aCvlx8Skw79jKjVRTsl+4B9bfOvkpxcwXfcAvz5Ktp2rbNf08V+TZdb8h9nrl9/f1Rx0qG/AGwe2t4EnLlwp6o6BBxazRckma+qudU179plv6aL/Zous9qvUSZ99c5XgW1Jtib5fmA3cHTCbZCkbk10pF9V7yX5N8CXgXXAZ6rqxCTbIEk9m/jNWVX1JeBLV/ErVjUtNAXs13SxX9NlVvt1kVRddB5VkjSjfOCaJHVkpkJ/Fh7xkGRzkv+R5LUkJ5I80uo3J3k+yettedNat3U1kqxL8rUkX2zbU9+vJB9J8vkk32h/bv94Rvr179rfwVeSfC7JB6exX0k+k+RckleGapfsR5IDLUNOJrl3bVp99cxM6A894uGngNuBn0ty+9q2alXeA36hqn4E2AE83PqxHzhWVduAY217Gj0CvDa0PQv9+nXg96rqHwIfZdC/qe5Xko3Ap4C5qrqTwYUXu5nOfj0F7LygNrIf7d/abuCOdszjLVtmxsyEPkOPeKiq7wLvP+JhqlTV2ar6k7b+DoMA2cigL4fbboeB+9ekgZchySbgPuDJofJU9yvJjcCPAZ8GqKrvVtV3mPJ+NdcBNyS5DvgQg3tqpq5fVfWHwLcvKF+qH7uAZ6rq3ap6AzjFIFtmxiyF/qhHPGxco7ZcEUm2AHcBLwK3VdVZGPxgAG5dw6at1q8Bvwh8b6g27f36IWAR+I02bfVkkg8z5f2qqv8L/CfgLeAs8P+q6veZ8n4NuVQ/Zi5HLjRLoT/WIx6mRZIfAH4b+Pmq+su1bs/lSvLTwLmqemmt23KFXQf8KPBEVd0F/DXTMeWxpDbHvQvYCvwg8OEkn1zbVk3ETOXIKLMU+mM94mEaJPkAg8D/bFV9oZXfTrKhvb8BOLdW7VuljwM/k+RNBlNvP5HkN5n+fi0AC1X1Ytv+PIMfAtPer58E3qiqxar6G+ALwD9h+vv1vkv1Y2Zy5FJmKfRn4hEPScJgfvi1qvrVobeOAnva+h7g2Um37XJU1YGq2lRVWxj82fxBVX2S6e/XnwGnk/xwK93D4FHhU90vBtM6O5J8qP2dvIfB+aVp79f7LtWPo8DuJNcn2QpsA46vQfuunqqamRfwCeB/A/8H+OW1bs8q+/BPGfx38k+Br7fXJ4C/y+Aqg9fb8ua1butl9PHHgS+29anvF/AxYL79mf034KYZ6devAN8AXgH+C3D9NPYL+ByD8xJ/w2Akv3epfgC/3DLkJPBTa93+K/3yjlxJ6sgsTe9IkpZh6EtSRwx9SeqIoS9JHTH0Jakjhr4kdcTQl6SOGPqS1JH/D4+pa9abhKTBAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recipe #0 length: 81\n",
      "Recipe #1 length: 81\n",
      "Recipe #2 length: 81\n",
      "Recipe #3 length: 81\n",
      "Recipe #4 length: 81\n",
      "Recipe #5 length: 81\n",
      "Recipe #6 length: 81\n",
      "Recipe #7 length: 81\n",
      "Recipe #8 length: 81\n",
      "Recipe #9 length: 81\n",
      "4 skinless boneless chicken breast halves 2 tablespoons butter 2 10 75 ounce cans condensed cream of chicken soup 1 onion finely diced 2 10 ounce packages refrigerated biscuit dough torn into pieces ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£\n"
     ]
    }
   ],
   "source": [
    "dataset_vectorized = tokenizer.texts_to_sequences(dataset_filtered)\n",
    "print('Vectorized dataset size', len(dataset_vectorized))\n",
    "print(dataset_vectorized[0][:10], '...')\n",
    "def recipe_sequence_to_string(recipe_sequence):\n",
    "    recipe_stringified = tokenizer.sequences_to_texts([recipe_sequence])[0]\n",
    "    print(recipe_stringified)\n",
    "recipe_sequence_to_string(dataset_vectorized[0])\n",
    "for recipe_index, recipe in enumerate(dataset_vectorized[:10]):\n",
    "    print('Recipe #{} length: {}'.format(recipe_index + 1, len(recipe)))\n",
    "\n",
    "recipes_lengths = []\n",
    "for recipe_text in dataset_vectorized:\n",
    "    recipes_lengths.append(len(recipe_text))\n",
    "\n",
    "plt.hist(recipes_lengths, bins=50)\n",
    "plt.show()\n",
    "MAX_PROC_RECIPE_LENGTH=80\n",
    "\n",
    "dataset_vectorized_padded_without_stops = tf.keras.preprocessing.sequence.pad_sequences(\n",
    "    dataset_vectorized,\n",
    "    padding='post',\n",
    "    truncating='post',\n",
    "    # We use -1 here and +1 in the next step to make sure\n",
    "    # that all recipes will have at least 1 stops sign at the end,\n",
    "    # since each sequence will be shifted and truncated afterwards\n",
    "    # (to generate X and Y sequences).\n",
    "    maxlen=MAX_PROC_RECIPE_LENGTH-1,\n",
    "    value=tokenizer.texts_to_sequences([STOP_SIGN])[0]\n",
    ")\n",
    "\n",
    "dataset_vectorized_padded = tf.keras.preprocessing.sequence.pad_sequences(\n",
    "    dataset_vectorized_padded_without_stops,\n",
    "    padding='post',\n",
    "    truncating='post',\n",
    "    maxlen=MAX_PROC_RECIPE_LENGTH+1,\n",
    "    value=tokenizer.texts_to_sequences([STOP_SIGN])[0]\n",
    ")\n",
    "\n",
    "for recipe_index, recipe in enumerate(dataset_vectorized_padded[:10]):\n",
    "    print('Recipe #{} length: {}'.format(recipe_index, len(recipe)))\n",
    "    \n",
    "recipe_sequence_to_string(dataset_vectorized_padded[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "direct-rabbit",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<RepeatDataset shapes: ((64, 80), (64, 80)), types: (tf.int32, tf.int32)>\n"
     ]
    }
   ],
   "source": [
    "def split_input_target(recipe):\n",
    "    input_text = recipe[:-1]\n",
    "    target_text = recipe[1:]\n",
    "    return input_text, target_text\n",
    "\n",
    "dataset = tf.data.Dataset.from_tensor_slices(dataset_vectorized_padded)\n",
    "dataset_targeted = dataset.map(split_input_target)\n",
    "\n",
    "BATCH_SIZE = 64\n",
    "SHUFFLE_BUFFER_SIZE = 1000\n",
    "dataset_train = dataset_targeted.shuffle(SHUFFLE_BUFFER_SIZE).batch(BATCH_SIZE, drop_remainder=True).repeat()\n",
    "#dataset_train = dataset_targeted.shuffle(SHUFFLE_BUFFER_SIZE).batch(BATCH_SIZE, drop_remainder=True)\n",
    "print(dataset_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "realistic-niagara",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (64, None, 256)           3262208   \n",
      "_________________________________________________________________\n",
      "gru (GRU)                    (64, None, 1024)          3938304   \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (64, None, 1024)          1049600   \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (64, None, 512)           524800    \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (64, None, 256)           131328    \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (64, None, 128)           32896     \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (64, None, 256)           33024     \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (64, None, 12743)         3274951   \n",
      "=================================================================\n",
      "Total params: 12,247,111\n",
      "Trainable params: 12,247,111\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "def build_model(vocab_size, embedding_dim, rnn_units, batch_size):\n",
    "    model = tf.keras.models.Sequential()\n",
    "\n",
    "    model.add(tf.keras.layers.Embedding(\n",
    "        input_dim=vocab_size,\n",
    "        output_dim=embedding_dim,\n",
    "        batch_input_shape=[batch_size, None]\n",
    "    ))\n",
    "\n",
    "    model.add(tf.keras.layers.GRU(\n",
    "        units=rnn_units,\n",
    "        return_sequences=True,\n",
    "        stateful=True,\n",
    "        recurrent_initializer=tf.keras.initializers.GlorotNormal()\n",
    "    ))\n",
    "\n",
    "    model.add(tf.keras.layers.Dense(1024))\n",
    "    model.add(tf.keras.layers.Dense(512))\n",
    "    model.add(tf.keras.layers.Dense(256))\n",
    "    model.add(tf.keras.layers.Dense(128))\n",
    "    model.add(tf.keras.layers.Dense(256))\n",
    "    model.add(tf.keras.layers.Dense(vocab_size))\n",
    "    return model\n",
    "\n",
    "model = build_model(\n",
    "  vocab_size=VOCABULARY_SIZE,\n",
    "  embedding_dim=256,\n",
    "  rnn_units=1024,\n",
    "  batch_size=BATCH_SIZE\n",
    ")\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "instrumental-sample",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_18\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_22 (InputLayer)           [(64, None)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_31 (Embedding)        (64, None, 32)       407776      input_22[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "gru_31 (GRU)                    (64, None, 1024)     3250176     embedding_31[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dense_184 (Dense)               (64, None, 1024)     1049600     gru_31[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dense_185 (Dense)               (64, None, 512)      524800      dense_184[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_186 (Dense)               (64, None, 256)      131328      dense_185[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_187 (Dense)               (64, None, 256)      65792       dense_186[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_188 (Dense)               (64, None, 512)      131584      dense_187[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_189 (Dense)               (64, None, 12743)    6537159     dense_188[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "tf.cast_36 (TFOpLambda)         (64, None)           0           input_22[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "tf.convert_to_tensor_55 (TFOpLa (64, None)           0           tf.cast_36[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "tf.convert_to_tensor_54 (TFOpLa (64, None, 12743)    0           dense_189[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "tf.cast_37 (TFOpLambda)         (64, None)           0           tf.convert_to_tensor_55[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "tf.convert_to_tensor_56 (TFOpLa (64, None, 12743)    0           tf.convert_to_tensor_54[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "tf.nn.sparse_softmax_cross_entr (64, None)           0           tf.cast_37[0][0]                 \n",
      "                                                                 tf.convert_to_tensor_56[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "add_loss_6 (AddLoss)            (64, None)           0           tf.nn.sparse_softmax_cross_entrop\n",
      "==================================================================================================\n",
      "Total params: 12,098,215\n",
      "Trainable params: 12,098,215\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# sampling function\n",
    "Z_DIM=128\n",
    "\n",
    "def sampling(args):\n",
    "    mu, log_var = args\n",
    "    #eps = tf.keras.backend.random_normal(shape=(None, Z_DIM), mean=0., stddev=1.0)\n",
    "    eps = tf.keras.backend.random_normal(shape=(MAX_PROC_RECIPE_LENGTH, Z_DIM), mean=0., stddev=1.0)\n",
    "    return mu + tf.keras.backend.exp(log_var) * eps\n",
    "\n",
    "\n",
    "def build_vae_model(vocab_size, embedding_dim, rnn_units,z_dim, batch_size):\n",
    "    input_recette = tf.keras.Input(batch_input_shape=(batch_size, None))\n",
    "    input_layer = tf.keras.layers.Embedding(\n",
    "        input_dim=vocab_size,\n",
    "        output_dim=embedding_dim,\n",
    "        batch_input_shape=[batch_size, None]\n",
    "    )(input_recette)\n",
    "    gru = tf.keras.layers.GRU(\n",
    "        units=rnn_units,\n",
    "        return_sequences=True,\n",
    "        stateful=True,\n",
    "        recurrent_initializer=tf.keras.initializers.GlorotNormal()\n",
    "    )(input_layer)\n",
    "    \n",
    "    #x_encoded = tf.keras.layers.Flatten()(gru)\n",
    "    x_encoded = tf.keras.layers.Dense(rnn_units, activation='relu')(gru)\n",
    "    x_encoded = tf.keras.layers.Dense(rnn_units//2, activation='relu')(x_encoded)\n",
    "    x_encoded = tf.keras.layers.Dense(rnn_units//4, activation='relu')(x_encoded)\n",
    "\n",
    "    #mu      = tf.keras.layers.Dense(z_dim)(x_encoded)\n",
    "    #log_var = tf.keras.layers.Dense(z_dim)(x_encoded)\n",
    "    #z       = tf.keras.layers.Lambda(sampling, batch_size=batch_size,output_shape=(z_dim,))([mu, log_var])    \n",
    "\n",
    "    # decoder\n",
    "    z_decoder0 = tf.keras.layers.Dense(rnn_units//4, activation='relu')(x_encoded)\n",
    "    z_decoder1 = tf.keras.layers.Dense(rnn_units//2, activation='relu')(z_decoder0)\n",
    "    z_decoder2 = tf.keras.layers.Dense(vocab_size, activation='relu')(z_decoder1)\n",
    "    vae = tf.keras.models.Model(input_recette, z_decoder2)\n",
    "    ae_loss = tf.keras.losses.sparse_categorical_crossentropy(\n",
    "      y_true=input_recette,\n",
    "      y_pred=z_decoder2,\n",
    "      from_logits=True\n",
    "    )\n",
    "    #kl_loss = 0.001 * tf.keras.backend.sum(tf.keras.backend.square(mu) + tf.keras.backend.exp(log_var) - log_var - 1, axis = -1)\n",
    "    vae_loss = ae_loss# + kl_loss\n",
    "    vae.add_loss(vae_loss)\n",
    "    return vae\n",
    "    \n",
    "model = build_vae_model(\n",
    "  vocab_size=VOCABULARY_SIZE,\n",
    "  embedding_dim=32,\n",
    "  rnn_units=1024,\n",
    "  z_dim=128,\n",
    "  batch_size=BATCH_SIZE\n",
    ")\n",
    "\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "german-point",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_10\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_10 (Embedding)     (64, None, 256)           3262208   \n",
      "_________________________________________________________________\n",
      "gru_10 (GRU)                 (64, None, 1024)          3938304   \n",
      "_________________________________________________________________\n",
      "dense_35 (Dense)             (64, None, 1024)          1049600   \n",
      "_________________________________________________________________\n",
      "dense_36 (Dense)             (64, None, 512)           524800    \n",
      "_________________________________________________________________\n",
      "dense_37 (Dense)             (64, None, 256)           131328    \n",
      "_________________________________________________________________\n",
      "dense_38 (Dense)             (64, None, 256)           65792     \n",
      "_________________________________________________________________\n",
      "dense_39 (Dense)             (64, None, 512)           131584    \n",
      "_________________________________________________________________\n",
      "dense_40 (Dense)             (64, None, 12743)         6537159   \n",
      "=================================================================\n",
      "Total params: 15,640,775\n",
      "Trainable params: 15,640,775\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "def build_vae2_model(vocab_size, embedding_dim, rnn_units,z_dim, batch_size):\n",
    "    model = tf.keras.models.Sequential()\n",
    "\n",
    "    model.add(tf.keras.layers.Embedding(\n",
    "        input_dim=vocab_size,\n",
    "        output_dim=embedding_dim,\n",
    "        batch_input_shape=[batch_size, None]\n",
    "    ))\n",
    "\n",
    "    model.add(tf.keras.layers.GRU(\n",
    "        units=rnn_units,#//4\n",
    "        return_sequences=True,\n",
    "        stateful=True,\n",
    "        recurrent_initializer=tf.keras.initializers.GlorotNormal()\n",
    "    ))\n",
    "    #model.add(tf.keras.layers.Flatten())\n",
    "    model.add(tf.keras.layers.Dense(rnn_units))\n",
    "    model.add(tf.keras.layers.Dense(rnn_units//2))#\n",
    "    model.add(tf.keras.layers.Dense(rnn_units//4))\n",
    "    ##model.add(tf.keras.layers.Dense(embedding_dim))\n",
    "    model.add(tf.keras.layers.Dense(rnn_units//4))\n",
    "    model.add(tf.keras.layers.Dense(rnn_units//2))\n",
    "    #model.add(tf.keras.layers.Dense(MAX_PROC_RECIPE_LENGTH))\n",
    "    model.add(tf.keras.layers.Dense(vocab_size))\n",
    "    #model.add(tf.keras.layers.Dense(vocab_size*MAX_PROC_RECIPE_LENGTH))\n",
    "    #model.add(tf.keras.layers.Reshape((MAX_PROC_RECIPE_LENGTH,vocab_size)))\n",
    "    return model\n",
    "    \n",
    "model = build_vae2_model(\n",
    "  vocab_size=VOCABULARY_SIZE,\n",
    "  embedding_dim=256, #small is 64\n",
    "  rnn_units=1024,#small \n",
    "  z_dim=128,\n",
    "  batch_size=BATCH_SIZE\n",
    ")\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "behavioral-courtesy",
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss(labels, logits):\n",
    "    #labels_reshape = tf.reshape(labels,[BATCH_SIZE,MAX_PROC_RECIPE_LENGTH])\n",
    "    #print(labels_reshape.shape,logits.shape)\n",
    "    entropy = tf.keras.losses.sparse_categorical_crossentropy(\n",
    "      y_true=labels,\n",
    "      y_pred=logits,\n",
    "      from_logits=True\n",
    "    )\n",
    "    #entropy = tf.keras.losses.mse(\n",
    "    #  y_true=labels,\n",
    "    #  y_pred=logits,\n",
    "    #  #from_logits=True\n",
    "    #)\n",
    "    return entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "honest-collection",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_10\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_10 (Embedding)     (64, None, 256)           3262208   \n",
      "_________________________________________________________________\n",
      "gru_10 (GRU)                 (64, None, 1024)          3938304   \n",
      "_________________________________________________________________\n",
      "dense_35 (Dense)             (64, None, 1024)          1049600   \n",
      "_________________________________________________________________\n",
      "dense_36 (Dense)             (64, None, 512)           524800    \n",
      "_________________________________________________________________\n",
      "dense_37 (Dense)             (64, None, 256)           131328    \n",
      "_________________________________________________________________\n",
      "dense_38 (Dense)             (64, None, 256)           65792     \n",
      "_________________________________________________________________\n",
      "dense_39 (Dense)             (64, None, 512)           131584    \n",
      "_________________________________________________________________\n",
      "dense_40 (Dense)             (64, None, 12743)         6537159   \n",
      "=================================================================\n",
      "Total params: 15,640,775\n",
      "Trainable params: 15,640,775\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "adam_optimizer = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
    "\n",
    "model.compile(\n",
    "    optimizer=adam_optimizer,\n",
    "    loss=loss\n",
    "    #loss=\"sparse_categorical_crossentropy\"\n",
    ")\n",
    "model.summary()\n",
    "early_stopping_callback = tf.keras.callbacks.EarlyStopping(\n",
    "    patience=5,\n",
    "    monitor='loss',\n",
    "    restore_best_weights=True,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Create a checkpoints directory.\n",
    "checkpoint_dir = 'tmp/checkpoints'\n",
    "os.makedirs(checkpoint_dir, exist_ok=True)\n",
    "\n",
    "checkpoint_prefix = os.path.join(checkpoint_dir, 'ckpt_{epoch}')\n",
    "checkpoint_callback=tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath=checkpoint_prefix,\n",
    "    save_weights_only=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "elect-intent",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'recipe_generation_rnn_raw_vae.h5'#recipe_generation_rnn_raw.h5'\n",
    "model.load_weights(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "senior-change",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCHS:           15\n",
      "INITIAL_EPOCH:    1\n",
      "STEPS_PER_EPOCH:  1500\n",
      "<RepeatDataset shapes: ((64, 80), (64, 80)), types: (tf.int32, tf.int32)>\n",
      "Epoch 2/15\n",
      "1500/1500 [==============================] - 80s 54ms/step - loss: 0.8807\n",
      "Epoch 3/15\n",
      "1500/1500 [==============================] - 80s 54ms/step - loss: 0.8753\n",
      "Epoch 4/15\n",
      "1500/1500 [==============================] - 80s 54ms/step - loss: 0.8720\n",
      "Epoch 5/15\n",
      "1500/1500 [==============================] - 81s 54ms/step - loss: 0.8688\n",
      "Epoch 6/15\n",
      "1500/1500 [==============================] - 81s 54ms/step - loss: 0.8662\n",
      "Epoch 7/15\n",
      "1500/1500 [==============================] - 80s 54ms/step - loss: 0.8632\n",
      "Epoch 8/15\n",
      "1500/1500 [==============================] - 80s 54ms/step - loss: 0.8621\n",
      "Epoch 9/15\n",
      "1500/1500 [==============================] - 81s 54ms/step - loss: 0.8615\n",
      "Epoch 10/15\n",
      "1500/1500 [==============================] - 81s 54ms/step - loss: 0.8571\n",
      "Epoch 11/15\n",
      "1500/1500 [==============================] - 80s 54ms/step - loss: 0.8611\n",
      "Epoch 12/15\n",
      "1500/1500 [==============================] - 80s 54ms/step - loss: 0.8624\n",
      "Epoch 13/15\n",
      "1500/1500 [==============================] - 80s 54ms/step - loss: 0.8605\n",
      "Epoch 14/15\n",
      "1500/1500 [==============================] - 80s 54ms/step - loss: 0.8592\n",
      "Epoch 15/15\n",
      "1500/1500 [==============================] - 80s 54ms/step - loss: 0.8575\n"
     ]
    }
   ],
   "source": [
    "EPOCHS = 15\n",
    "INITIAL_EPOCH = 1\n",
    "STEPS_PER_EPOCH = 1500\n",
    "\n",
    "print('EPOCHS:          ', EPOCHS)\n",
    "print('INITIAL_EPOCH:   ', INITIAL_EPOCH)\n",
    "print('STEPS_PER_EPOCH: ', STEPS_PER_EPOCH)\n",
    "print(dataset_train)\n",
    "tf.train.latest_checkpoint(checkpoint_dir)\n",
    "history = model.fit(\n",
    "    x=dataset_train,\n",
    "    #y=dataset_train,\n",
    "    epochs=EPOCHS,\n",
    "    steps_per_epoch=STEPS_PER_EPOCH,\n",
    "    initial_epoch=INITIAL_EPOCH,\n",
    "    callbacks=[\n",
    "        checkpoint_callback\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Saving the trained model to file (to be able to re-use it later).\n",
    "model_name = 'recipe_generation_rnn_raw_vae.h5' #note raw vae is rnn:1024 and embedding dim=256\n",
    "model.save(model_name, save_format='h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "received-bunch",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAY4AAAEWCAYAAABxMXBSAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8rg+JYAAAACXBIWXMAAAsTAAALEwEAmpwYAABDIElEQVR4nO29e3xU1bm4/7wkIQMEGGBCBjJAIEFCQAxVwfu1KLXW26lV61GPraX01IrW02rt6am92Fpr6+XUfj229ej51Yq21hYtVdGqeKtcJNxCkABBAwQcQoBAAgm8vz9mMk5ikslldmbP5n0+n/lk9t5r7VlP1mS/2XvdRFUxDMMwjK7SL9UFMAzDMNILCxyGYRhGt7DAYRiGYXQLCxyGYRhGt7DAYRiGYXQLCxyGYRhGt7DAYRiGYXQLCxyGkUREpEpEPp3qchiGk1jgMAzDMLqFBQ7DcBgRyRaR+0VkW/R1v4hkR48FROR5EakTkVoReUNE+kWP3SYiW0Vkn4isF5FzU2tiGBEyU10AwzgK+C5wElAKKPBX4D+B7wG3AtVAbjTtSYCKyCTgRuBEVd0mIgVARt8W2zDax+44DMN5rgZ+qKo7VfUj4AfANdFjTcAoYJyqNqnqGxqZQO4wkA2UiEiWqlap6saUlN4w2mCBwzCcZzSwJW57S3QfwM+BSuAlEdkkIrcDqGolcDNwJ7BTROaLyGgMwwVY4DAM59kGjIvbHhvdh6ruU9VbVXUC8Dngmy1tGar6B1U9LZpXgZ/1bbENo30scBhG8skSEV/LC3gS+E8RyRWRAPBfwO8BRORCESkSEQH2EnlEdVhEJonIOdFG9EagIXrMMFKOBQ7DSD4LiVzoW14+YBmwClgNvAf8OJp2IvAyUA+8A/xaVV8j0r5xNxAGaoCRwB19ZmAYnSC2kJNhGIbRHeyOwzAMw+gWFjgMwzCMbmGBwzAMw+gWFjgMwzCMbnFUTDkSCAS0oKCgR3mbm5vJzPTGr8lc3IdXPMBc3EpvXJYvXx5W1dy2+73xm0lAQUEBy5Yt61HehoYGBgwYkOQSpQZzcR9e8QBzcSu9cRGRLe3tt0dVhmEYRrewwJGALVvaDbhpibm4D694gLm4FSdcHA0cIjI7uo5AZcvkbW2ODxORZ0VklYgsEZGp0f1jRORVEVknImtFZF5cnjujaxSURV8XOOlgGIZhtMaxNg4RyQAeAmYRWW9gqYgsUNXyuGR3AGWqeqmIFEfTnws0A7eq6nsiMhhYLiKL4vLep6r3OlV2wzBSR1NTE9XV1TQ2Nqa0DOvWrUvZ5yeTrrj4fD5CoRBZWVldOqeTjeMzgEpV3QQgIvOBi4H4wFEC/BRAVStEpEBE8lR1O7A9un+fiKwD8tvk7RMCgUBff6RjmIv78IoHJM+lurqawYMHU1BQQGTux76nqampyxdRt5PIRVXZtWsX1dXVjB8/vkvndPJRVT7wYdx2dXRfPCuBywBEZAaR6aND8QmiK59NB96N231j9PHWoyIyLMnlboX9YbsTr7h4xQOS59LY2MiIESNSFjQAzwQNSOwiIowYMaJbd3hO3nG0V+ttZ1S8G3hARMqIzBq6gshjqsgJRHKAZ4CbVXVvdPf/A34UPdePgF8AX/rEh4vMAeYAhEIhKioqYsfGjYssjRDfaBQIBAgEAlRWVtLcHCmCz+ejubmZnJwc6urqYmkLCwtpbGxk69atsX3BYBC/39/qc3JycgiFQlRXV1NfXx/bX1xcTF1dHTU1NbF9+fn5+Hw+Nm78eJE3v99PMBikqqoqVqmZmZkUFRURDocJh8PdcqqtrWX06NEUFBRQU1OT1k7//Oc/8fv9QKSe0tWptraWY445pt3vXro5rVixguHDh7eqp544NTU1cfjwYTIzM2loaIily8jIoH///hw6dIjDhz+eYX7AgAE0NzfT1NQU29e/f39EhIMHD8b2ZWZmkpWVxcGDBzly5AgQuWj6fD6amppi5WwhOzu73fyNjY20TA7br18/srOzP5E/OzsbVeXQoUOxfVlZWSlxOnz4MBkZGWRnZwN0mL+pqYmKiopW9dQhqurICzgZeDFu+zvAdzpJL0AVMCS6nQW8CHyzkzwFwJpEZTn++OO1JyyrqtUfPP12j/K6kXXr1qW6CEnDKy5e8VBNnkt5eXlSztMbDhw4kOoiJI2uurT3eweWaTvXVCcfVS0FJorIeBHpD1wJLIhPICL+6DGAG4DFqro3uqjN74B1qvrLNnlGxW1eCqxxSuC5ldt4dHktr63f6dRHGIbhMnbt2sXMmTMpLS0lGAySn59PaWkppaWlre4g2mPZsmXcdNNNCT/jlFNOSVZxu8VPfvKTpJzHscChqs3AjUTuGtYBT6vqWhGZKyJzo8kmA2tFpAL4DNDS7fZU4BrgnHa63d4jIqtFZBVwNnCLUw63f6aY8cOz+Y8/riJcfzBxBpfj8/lSXYSk4RUXr3iAd1xGjBjB0qVLKSsrY+7cudxyyy2UlZVRVlZG//79P/FIK54TTjiBBx98MOFnvP3228kscqf06/fxZd71gQNAVReq6jGqWqiqd0X3PayqD0ffv6OqE1W1WFUvU9Xd0f1vqqqo6jRVLY2+FkaPXaOqx0aPXaSRHliO4MvK4OFrZ7K3sYlv/XFl7LlmutLT+brciFdcvOIB3nJpaQ9o4d/+7d/45je/ydlnn81tt93GkiVLOOWUU5g+fTqnnHIK69evB+C1117jwgsvBODOO+/kS1/6EmeddRYTJkxoFVBycnJi6c866yw+//nPU1xczNVXXx27zixcuJDi4mJOO+00brrppth541m7di0zZsygtLSUadOmsWHDBgB+//vfx/bfdNNNHD58mNtvv52GhgZKS0u5+uqre/X7OSrmquoNQ9nPHZ8p5s7nynn87Sr+7dSudVdzIzU1NQSDwVQXIyl4xcUrHuCMyw+eW0v5tr2JE3aDktFD+P7npnSapr0urO+//z4vv/wyGRkZ7N27l8WLF5OZmcnLL7/MHXfcwTPPPPOJ81RUVPDqq6+yb98+Jk2axNe+9rVPnHfFihWsXbuW0aNHc+qpp/LWW29xwgkn8NWvfpXFixczfvx4rrrqqnbL+fDDDzNv3jyuvvrqWAP7unXreOqpp3jrrbfIyspi7ty5PPHEE9x999386le/oqysrHu/sHawwJGAuro6rjtlEq+//xE/+XsFJxWOoDg4JNXF6hF1dXWeuUh5xcUrHuAtl+bm5k9c4C+//HIyMjIA2LNnD9dddx0bNmxARFr1forns5/9LNnZ2WRnZzNy5Eh27NhBKNRqxAEzZsyI7SstLaWqqoqcnBwmTJgQG1dx1VVX8cgjj3zi/CeffDJ33XUX1dXVXHbZZUycOJFXXnmF5cuXc+KJJwJw4MCBpNeLBY4uICL8/PLjmH3/G9z05AoW3HgavqyMVBfLMDxPojuDvmTQoEGx99/73vc4++yzefbZZ6mqquKss85qN0/8I6+MjIx220faS9PVx+Jf/OIXmTlzJn/72984//zz+e1vf4uqct111/HTn/4UcGamX5vksIsEcrK59/JpvL+jnp8u9MZUBIZh9Iw9e/aQnx8Zz/zYY48l/fzFxcVs2rSJqqoqAJ566ql2023atIkJEyZw0003cdFFF7Fq1SrOPfdc/vSnP7FzZ6Q3aG1tbWzcUFZWVod3R93BAkcCCgsLY+/PmjSSL506nsff2cI/KnaksFQ9I94l3fGKi1c8wFsubRvH2/Ltb3+b73znO5x66qmtBu4liwEDBvDrX/+a2bNnc9ppp5GXl8fQoUM/ke6pp55i6tSplJaWUlFRwbXXXktJSQk//vGPOe+885g2bRoXXXQR27dH+hDNmTOHadOm9bpxXNK9p1BXOOGEE7SnCznt27ePwYMHx7YPNh/mkofeZsfeRl64+XRGDk6fLohtXdIZr7h4xQOS57Ju3TomT56chBL1nJbR1qmkvr6enJwcVJWvf/3rTJw4kVtu6f7og666tPd7F5HlqnpC27R2x5GA+KkdALIzM3jwylL2H2zm1qdXcuRI+gTeti7pjFdcvOIB3nJJNNCvL/jNb35DaWkpU6ZMYc+ePXz1q1/t0XmccLHA0QMm5g3mexeW8MaGMI++tTnVxTEMw4O0DDwsLy/niSeeYODAgakuUgwLHD3k6pljmVWSxz0vrGfttj2pLo5heIqj4RG6m+ju79sCRwI66v8sIvzsX6bhH5jFTU+uoOFQ8hvIko1X+tiDd1y84gHJc/H5fOzatSulweNomlZdo+txdGfKGGsc7yVvbgjzr797l6tnjuWuS4915DMM42jCDSsAHm10tAJgR43jNgAwARUVFRQXF3d4/LSJAb56xgT+Z/Emzjgml/OnuPc/yEQu6YRXXLziAclzycrK6vJKdE5h9dI59qgqCdx63iSm5g/htmdWUbPH/ksyDMPbWOBIAv0z+/HAldM52HSEW/9YllZddA3DMLqLBY4EtEx/nIjC3By+/7kS3qrcxW/e2ORwqXpGV13SAa+4eMUDzMWtOOFijeNJRFX59yfeY1H5Dp7991M5NvTJKQIMwzDShZSMHBeR2SKyXkQqReT2do4PE5FnRWSViCwRkanR/WNE5FURWScia0VkXlye4SKySEQ2RH8Oc9Khurq6y2lFhJ9ediy5g7O5af4K9h/seKWwVNAdF7fjFReveIC5uBUnXBwLHCKSATxEZEnYEuAqESlpk+wOoExVpwHXAg9E9zcDt6rqZOAk4OtxeW8HXlHVicAr0W3HqK+v71Z6/8D+/PILpVTt2s8Pnyt3qFQ9o7subsYrLl7xAHNxK064OHnHMQOoVNVNqnoImA9c3CZNCZGLP6paARSISJ6qblfV96L79xFZszw/mudi4PHo+8eBSxx06BEnF47ga2cW8tSyD1m42rGVbQ3DMFKCk+M48oEP47argZlt0qwELgPeFJEZwDggBMTmLBeRAmA68G50V17LOuOqul1ERrb34SIyB5gDEAqFqKioiB0bN24cQGyOeoBAIEAgEKCysjK22ErLSMqamhrq6upiaQsLC2lsbGw1qVswGMTv98c+54KxyqsjB3D7M6vIy2xgkHw80VhxcTF1dXXU1NR8/MvKz8fn87Fx48bYPr/fTzAYpKqqKjYYKjMzk6KiIsLhMOFwuFtO4XCYqqoqCgoKeuQEkYa2UChEdXV1q/9k+tqptrY2Vi6fz5e2Ti3H2/vupZtTOByOlaGjv6d0cWpubqahoaFL1wi3O7XUS3euey1OHeFY47iIXA6cr6o3RLevAWao6jfi0gwh8nhqOrAaKAZuUNWV0eM5wOvAXar65+i+OlX1x51jt6p22s7RV43jbakK7+eCB9/g2Pyh/OErJ5HRT/q8DIZhGD0lFY3j1cCYuO0QsC0+garuVdXrVbWUSBtHLrAZQESygGeAJ1qCRpQdIjIqmmYUsNMxA2j1X0R3KQgM4gcXTeHdzbU8/PrGxBkcpjcubsMrLl7xAHNxK064OBk4lgITRWS8iPQHrgQWxCcQEX/0GMANwGJV3SsiAvwOWKeqv2xz3gXAddH31wF/dcwAOr1d6wqfPz7EhdNGcd+i9yn7sC45heohvXVxE15x8YoHmItbccLFscChqs3AjcCLRBq3n1bVtSIyV0TmRpNNBtaKSAWR3lct3W5PBa4BzhGRsujrguixu4FZIrIBmBXddi0iwl2XHkveEB/z5q+g3mVddA3DMLqLo5McqupCYGGbfQ/HvX8HmNhOvjeBdhsEVHUXcG5yS+osQwdkcd8VpVz5yDt8/69r+cUXjkt1kQzDMHqMTTmSgPz8/MSJusCM8cO58ewinnmvmgUrtyXO4ADJcnEDXnHxigeYi1txwsUCRwK6s7hJIm46dyKfGuvnu8+upnr3gaSdt6sk0yXVeMXFKx5gLm7FCRcLHAmI7zPdWzIzIrPoqsLN88toPnwkaefuCsl0STVecfGKB5iLW3HCxQJHHzNm+EB+fMlUlm3ZzUOveufLaRjG0YMFjhRwyfR8LikdzYP/2MDyLbWpLo5hGEa3sMCRAL/f78h5f3jJVEb7fcybX8bexiZHPqMtTrmkAq+4eMUDzMWtOOFigSMBwaAza4gP8WVx/xXT2b6nkf/6yxpHPqMtTrmkAq+4eMUDzMWtOOFigSMBVVVVjp37+HHDmHfuRP5Sto1nVzg//7+TLn2NV1y84gHm4laccLHAkYCWGSed4utnF3FiwTC+95e1fLDL2S66Trv0JV5x8YoHmItbccLFAkeKyegn3HdFKSIw76kVNPVxF13DMIzuYoEjAZmZjs7KAkBo2EB+cumxrPigjv9+ZYNjn9MXLn2FV1y84gHm4laccHFsPQ43kar1OLrLf/xxJX9+r5r5c05mxvjhqS6OYRhHOalYj8MTxK8K5jR3XjSFMcMHcvP8Few5kPwuun3p4jRecfGKB5iLW3HCxQJHAvryC5STnckDV05n576D3PGX1ST7btD+GNyHVzzAXNyKBY6jgNIxfm6ZdQx/W7WdPy13vouuYRhGd3E0cIjIbBFZLyKVInJ7O8eHicizIrJKRJaIyNS4Y4+KyE4RWdMmz50isrWdBZ48w9wzC5k5fjjfX7CWzeH9qS6OYRhGKxwLHCKSATxEZGW/EuAqESlpk+wOoExVpxFZc/yBuGOPAbM7OP19qloafS3sIE1SGDdunJOnb5eWLrpZGf2YN38Fh5qT00U3FS5O4RUXr3iAubgVJ1ycvOOYAVSq6iZVPQTMBy5uk6YEeAVAVSuAAhHJi24vBo7aGQBH+wdw92XHsqp6D/e9/H6qi2MYhhHDyc7K+cCHcdvVwMw2aVYClwFvisgMYBwQAnYkOPeNInItsAy4VVV3t00gInOAOQChUIiKiorYsZYIvGXLlti+QCBAIBCgsrKS5ubIuuA+n4/Gxkb8fj91dXWxtIWFhTQ2NrJ169bYvmAwiN/vb/U5OTk5hEIhqqurqa+vj+0vLi6mrq6u1SLy+fn5+Hy+VnPnT8/1c+WJY3j4tY0UZDdw3KgBZGZmUlRURDgcbtXo1RWncDhMKBSioKCAmpqalDj5/X6CwSBVVVWxEa09cVqxYgXDhw+P1VO6OoXDYYqLi9v97qWb0/LlywkEAq3qKV2dmpubKSws7NI1wu1O4XCYQCDQretei1NHODaOQ0QuB85X1Rui29cAM1T1G3FphhB5PDUdWA0UAzeo6sro8QLgeVWNb/vIA8KAAj8CRqnqlzorS2/GcVRUVFBcXNyjvMngwKFmLnzwTQ4cOswLN5+Of2D/Hp8r1S7JxCsuXvEAc3ErvXFJxTiOamBM3HYIaLXYtqruVdXrVbWUSBtHLrC5s5Oq6g5VPayqR4DfEHkk5lkG9o900d21/yC3P5P8LrqGYRjdxcnAsRSYKCLjRaQ/cCWwID6BiPijxwBuABar6t7OTioio+I2LwUcnZO85dY7lRwbGsp/nDeJF9bW8NTSDxNn6AA3uCQLr7h4xQPMxa044eJY4FDVZuBG4EVgHfC0qq4VkbkiMjeabDKwVkQqiPS+mteSX0SeBN4BJolItYh8OXroHhFZLSKrgLOBW5xyAPd8gb5y+gROLRrBD54rZ+NH9YkztINbXJKBV1y84gHm4laccLG5qhJQWVlJUVFRkkvUM3bsbWT2/YsZ7R/An//9FLIzM7qV300uvcUrLl7xAHNxK71xsbmqekhLTwM3kDfEx8/+ZRprt+3lFy91v4uum1x6i1dcvOIB5uJWnHCxwJFmnDclyNUzx/LI4k28ucE78+kYhpE+WOBIgM/nS3URPsF/fraEopE5fPPpMmr3H+pyPje69BSvuHjFA8zFrTjhYm0caUr5tr1c8tBbnHFMLr+59nhEJNVFMgzDY1gbRw/pbPRkKikZPYTbPlPMy+t28Pt3P+hSHre69ASvuHjFA8zFrTjhYoEjAfHTCLiN608p4Ixjcvnx8+Vs2LEvYXo3u3QXr7h4xQPMxa044WKBI43p10+49/Jp5GRn8o0nV9DYdDjVRTIM4yjAAkeaM3Kwj59fPo2Kmn3c88L6VBfHMIyjAAscCSgsLEx1ERJyTnEe1508jkff2sxr63d2mC4dXLqKV1y84gHm4laccLHAkYCWqYrdzncumMykvMH8xx9X8tG+g+2mSReXruAVF694gLm4FSdcLHAkIH4+fTfjy8rgwaums7exmW//aWW7s+imi0tX8IqLVzzAXNyKEy4WODzEpOBgvnvBZF5d/xGPv12V6uIYhuFRLHB4jGtPHsc5xSP5yd8rqKjpdIZ6wzCMHmGBIwHBYDDVRegWIsI9n5/GEF8WN7XpoptuLp3hFReveIC5uBUnXCxwJMDv96e6CN0mkJPNL75wHO/vqOenC9fF9qejS0d4xcUrHmAubsUJFwscCYhfWD6dOPOYXL582ngef2cLr6zbAaSvS3t4xcUrHmAubsUJF0cDh4jMFpH1IlIpIre3c3yYiDwrIqtEZImITI079qiI7BSRNW3yDBeRRSKyIfpzmJMO6cy3Z09i8qghfOtPq9i51zvdCw3DSC2OBQ4RyQAeIrIkbAlwlYiUtEl2B1CmqtOAa4EH4o49Bsxu59S3A6+o6kTglei20Q7ZmRk8eGUpBw41c+sfV3LkKJgJ2TAM53HyjmMGUKmqm1T1EDAfuLhNmhIiF39UtQIoEJG86PZioLad814MPB59/zhwSfKL/jE5OTlOnt5xJuYN5j8/W8IbG8L8faN37jrSvV5a8IoHmItbccIlM+ln/Jh84MO47WpgZps0K4HLgDdFZAYwDggBOzo5b56qbgdQ1e0iMrK9RCIyB5gDEAqFWj3nGzduHABbtmyJ7QsEAgQCASorK2NLLfp8PgoKCqipqWk1w2RhYSGNjY2tBtYEg0H8fn+rz8nJySEUClFdXU19fX1sf3FxMXV1da2mO87Pz8fn87Fx48bYPr/fTzAYpKqqKjb6MzMzk6KiIsLhMOHwxysAduY0c8QhTh4zkIff3sa0oI9ZJ0xOe6fGxsZYudK9nsLhsCe+e/X19bEyeOHvqaGhwTPXiIqKih5d9zrCsYWcRORy4HxVvSG6fQ0wQ1W/EZdmCJHHU9OB1UAxcIOqroweLwCeV9X4to86VfXHbe9W1U7bOXqzkFN1dTWhUKhHed1E7f5DzPrFq/gHZfP8N05nQP+MVBepV3ilXrziAebiVnrjkoqFnKqBMXHbIWBbfAJV3auq16tqKZE2jlxgc4Lz7hCRUQDRnx3P6pcE4v8LSGeGD+rPf5yWy6bwfn70t/JUF6fXeKVevOIB5uJWnHBxMnAsBSaKyHgR6Q9cCSyITyAi/ugxgBuAxaqaaLjzAuC66PvrgL8mscyeZvrogcw5fQJ/ePcDXlzrnRXODMPoWxwLHKraDNwIvAisA55W1bUiMldE5kaTTQbWikgFkd5X81ryi8iTwDvAJBGpFpEvRw/dDcwSkQ3ArOi20UVuPW8SU/OHcNszq6jZ453GcsMw+g7H2jjcRG/aOLzIxo/qufDBN5k+1s/vvzyTfv0k1UUyDMOFpKKNwxN4ce3hwtwc7ryohLc37uKRNzaltlA9xCv14hUPMBe3YmuOp4DOuqSlG/EuXzhhDJ+ZGuTeF9ezqroudYXqIV6pF694gLm4FSdcLHAcpYgIP73sWHIHZzNvfhn7DzanukiGYaQJFjiOYvwD+/PLL5RStWs/P3wu/bvoGobRN1jgSEB+fn6qi5A02nM5uXAEXzuzkKeWfcjC1dtTUKqe4ZV68YoHmItbccLFAkcCfD5fqouQNDpyuWXWMRwXGsrtz6xiW11DH5eqZ3ilXrziAebiVpxwscCRgPh5YdKdjlyyMvrxwJXTOXxEufmpMg4fcX8Xba/Ui1c8wFzcihMuFjgMAAoCg/jBxVNZsrmWh1/3zh+NYRjJxwKHEeNfPpXPhdNG8ctF77Pig92pLo5hGC7FAkcCjqa1h0WEuy49luAQH/Pml1Hv4i66XqkXr3iAubgVW3M8BQSDwVQXIWl0xWXogCzuv7KU6t0H+P5f1/ZBqXqGV+rFKx5gLm7FCRcLHAmoqqpKdRGSRlddTiwYzo3nTOSZ96pZsHJb4gwpwCv14hUPMBe34oSLBY4EtKyq5QW643LTOUV8aqyf7z67mg9rDzhYqp7hlXrxigeYi1txwsUCh9EumdEuuqpwy1NlNB8+kuoiGYbhEroUOERkkIj0i74/RkQuEpEsZ4vmDjIznVyWvW/prsuY4QP58SVTWbZlNw+96q4uul6pF694gLm4FSdcunrHsRjwiUg+8ApwPfBYokwiMltE1otIpYjc3s7xYSLyrIisEpElIjI1UV4RuVNEtopIWfR1QRcdekRRUZGTp+9TeuJyyfR8Lp2ezwOvvM/yLbUOlKpneKVevOIB5uJWnHDpauAQVT0AXAb8t6peCpR0mkEkA3iIyMp+JcBVItI2zx1AmapOI7Lm+ANdzHufqpZGXwu76NAjwuGwk6fvU3rq8sOLp5A/bADz5pext7EpyaXqGV6pF694gLm4FSdcuhw4RORk4Grgb9F9ie5/ZgCVqrpJVQ8B84GL26QpIXIHg6pWAAUiktfFvH2CfYFgsC+L+6+YzvY9jXzvL2uSXKqe4ZV68YoHmItbccKlqw+/bga+AzwbXTd8AvBqgjz5wIdx29XAzDZpVhK5i3lTRGYA44BQF/LeKCLXAsuAW1X1E8OcRWQOMAcgFApRUVEROzZu3DgAtmzZEtsXCAQIBAJUVlbS3BwZ+NYyOVhNTU2rVbQKCwtpbGxk69atsX3BYBC/39/qc3JycgiFQlRXV1NfXx/bX1xcTF1dXasFVvLz8/H5fK3mlfH7/QSDQaqqqmI9IzIzMykqKiIcDrf6QnTFKRwOU1VVRUFBQbedBgFfPM7P/7diG2dNyuXEXFLqVFtbG/td+3y+Hjm5oZ5ajrf33Us3p3A4HCtDR39P6eLU3NxMQ0NDl64RbndqqZfuXPdanDqi22uORxvJc1R1b4J0lwPnq+oN0e1rgBmq+o24NEOIPJ6aDqwGioEbgGM6yhu9IwkDCvwIGKWqX+qsLL1Zc7yiooLi4uIe5XUbvXU5fES58pF3WLd9HwtvOp2xIwYmsXTdwyv14hUPMBe30huXXq05LiJ/EJEhIjIIKAfWi8i3EmSrBsbEbYeAVqPJVHWvql6vqqVE2jhygc2d5VXVHap6WFWPAL8h8ljLMVqitBforUtGP+G+K0oRgZvmr6AphV10vVIvXvEAc3ErTrh0tY2jJHqHcQmwEBgLXJMgz1JgooiMF5H+wJXAgvgEIuKPHoPIncbi6Od0mFdERsWd4lLAHQ/djxJCwwbyk0uPpezDOh58ZUOqi2MYRgroauDIio7buAT4q6o2EXlU1CGq2gzcCLwIrAOejraPzBWRudFkk4G1IlJBpAfVvM7yRvPcIyKrRWQVcDZwSxcdekT888B0J1kunztuNJ8/PsRDr1by7qZdSTlnd/FKvXjFA8zFrTjh0tXG8f8Bqog0Zi8WkXFAp20cANGusgvb7Hs47v07wMSu5o3uT3SnY/QBd140haVVtdzyVBl/n3cGQwceFeNBDcOgi3ccqvqgquar6gUaYQuR//aNo5Sc7EweuHI6O/cd5I6/rKa7nSwMw0hfuto4PlREfikiy6KvXwCDHC6bKwgEAqkuQtJItkvpGD+3zDqGv63azh+XVyf13InwSr14xQPMxa044dLVNo5HgX3AF6KvvcD/Jr00LsS+QJ0z98xCTpownDsXrGVzeH/Sz98RXqkXr3iAubiVVAaOQlX9fnQk9yZV/QEwIemlcSGVlZWpLkLScMKlpYtuVkY/5s1fwaHmvumi65V68YoHmItbccKlq4GjQUROa9kQkVOBhqSXxoW0jKb0Ak65jBo6gLsvO5ZV1Xu47+X3HfmMtnilXrziAebiVpxw6WqvqrnA/4nI0Oj2buC6pJfGSFs+c+worjxxDA+/vpHTJwY4pdA7t/qGYbSmq72qVqrqccA0YJqqTgfOcbRkLqFlviov4LTLf32uhPEjBvHNp1aye/8hRz/LK/XiFQ8wF7fihEu356qKZRT5QFXHJrk8jtCbuaqM7rFm6x4u/fVbnFucx//7108hIqkukmEYPaRXc1V1dM5e5E0bOpshMt3oC5ep+UP51vmTeGFtDfOXfpg4Qw/xSr14xQPMxa044dKbwHFUjPiKnyo53ekrlxtOm8BpRQF++Fw5lTvrE2foAV6pF694gLm4FSdcOg0cIrJPRPa289oHjE56aQxP0K+f8IsvHIcvK9JF92Dz4VQXyTCMJNJp4FDVwao6pJ3XYFX1zmruRtLJG+Ljns8fx9pte/nFS33TRdcwjL6hN4+qjgoKCwtTXYSk0dcus0ry+NeTxvLI4k28seGjpJ7bK/XiFQ8wF7fihIsFjgS0LMfoBVLh8t0LSigamcOtT69kV/3BpJ3XK/XiFQ8wF7fihIsFjgTErxmc7qTCZUD/DB68cjp1B5q47ZlVSZtF1yv14hUPMBe34oSLBQ7DcUpGD+G2zxTz8rqd/P7dD1JdHMMweomjgUNEZovIehGpFJHb2zk+TESeFZFVIrJERKYmyisiw0VkkYhsiP4c5qSDkRyuP6WAM47J5cfPl/P+jn2pLo5hGL3AscAhIhnAQ0SWhC0BrhKRkjbJ7gDKVHUacC3wQBfy3g68oqoTgVei244RDAadPH2fkkqXfv2Eey+fRk52Jjc9uYLGpt510fVKvXjFA8zFrTjh4uQdxwygMjoN+yFgPnBxmzQlRC7+qGoFUCAieQnyXgw8Hn3/OJF10B3D7/c7efo+JdUuIwf7+Pnl06io2cfPXqjo1blS7ZIsvOIB5uJWnHBxcixGPhA/50Q1MLNNmpXAZcCbIjIDGAeEEuTNU9XtAKq6XURGtvfhIjIHmAMQCoWoqPj4QjVu3Dig9SLugUCAQCBAZWVlbBpin89HY2Mjfr+/1ejLwsJCGhsbWzU6BYNB/H5/q8/JyckhFApRXV1Nff3HI6iLi4upq6trNRVAfn4+Pp+PjRs3xvb5/X6CwSBVVVWxnhGZmZkUFRURDocJh8PdcgqHw4RCIQoKCqipqUmJU4nfz7+dUsD/vlXFhAGNnBga1COnt99+m+HDh8fqKZVOvamncDhMcXFxu9+9dHNavnx5bNGgjv6e0sWpubmZwsLCLl0j3O4UDocJBALduu61OHVEjyc5TISIXA6cr6o3RLevAWao6jfi0gwh8nhqOrAaKAZuAI7pKK+I1KmqP+4cu1W103aO3kxyWFFRQXFxcY/yug23uDQ2HebiX73Frv0H+fu8M8gdnN3tc7jFpbd4xQPMxa30xsWJSQ4TUQ2MidsOAdviE6jqXlW9XlVLibRx5AKbE+TdISKjAKI/dzpSesMxfFkZPHjVdPY2NvOtP61MWhddwzD6BicDx1JgooiMF5H+wJXAgvgEIuKPHoPIncZiVd2bIO8CPl5E6jrgrw46kJOT4+Tp+xQ3uUwKDua7F0zmtfUf8djbVd3O7yaX3uAVDzAXt+KEi2OPqgBE5ALgfiADeFRV7xKRuQCq+rCInAz8H3AYKAe+rKq7O8ob3T8CeBoYC3wAXK6qtZ2Vw9bjcCeqypcfX8ablWH++vVTmTxqSKqLZBhGHB09qnI0cLiF3gSO6upqQqFQkkuUGtzoEq4/yOz732DYwCye+8Zp+LIyupTPjS49wSseYC5upTcuqWjj8ATxPR3SHTe6BHKy+cUXjmPDznp+snBdl/O50aUneMUDzMWtOOFigcNIOWcek8uXTxvP/72zhVfW7Uh1cQzDSIAFDsMVfHv2JCaPGsK3/rSKnXu9MzOpYXgRa+MwXEPlzn1c+N9vcmLBcB6/fgb9+h0Vy9obhmuxNo4eYmsP9x1FIwfzvQtLeGNDmEff2txpWre7dBWveIC5uJU+X3PcoNNh9+lGOrh8ccZYZpXk8bMXKlizdU+H6dLBpSt4xQPMxa044WKBw3AVIsLP/mUawwf1Z978FTQc6t0suoZhJB8LHIbrGD6oP7/8Qimbwvv50d/KU10cwzDaYIEjAfn5+akuQtJIJ5dTiwLMOX0Cf3j3A15Y88lb7XRy6QyveIC5uBUnXCxwJMDn86W6CEkj3VxuPW8SU/OHcPufV1Gzp3UX3XRz6QiveIC5uBUnXCxwJCB+7vt0J91c+mf244Erp3Ow6QjffLqMI0c+7jqebi4d4RUPMBe34oSLBQ7D1RTm5nDnRSW8vXEXj7yxKdXFMQwDCxxGGvCFE8bwmalB7n1xPauq61JdHMM46rHAkQBbezj1iAg/vexYcgdnM29+GfsPNqetS1u84gHm4laccLHAkYBgMJjqIiSNdHbxD+zPfVeUUrVrPz94bm1au8TjFQ8wF7fihIujgUNEZovIehGpFJHb2zk+VESeE5GVIrJWRK6POzZPRNZE998ct/9OEdkqImXR1wVOOlRVVTl5+j4l3V1OmjCCfz+rkKeXVXP5Q6/zxLtb0n5CxHSvk3jMxZ044ZKZ9DNGEZEM4CFgFpE1xJeKyAJVjR/R9XWgXFU/JyK5wHoReQI4BvgKMAM4BLwgIn9T1Q3RfPep6r1OlT2exsb0vjDF4wWXmz99DAB/XraF7z67hu8+u4bSMX5mleRx/pQ8CnNzEEmfyRG9UCctmIs7ccLFscBB5KJfqaqbAERkPnAxkSViW1BgsET+0nOAWqAZmAz8U1UPRPO+DlwK3ONgeY00ICujH986v5gLxyr9hoVYVF7DS+U7+PmL6/n5i+sZHxjEeSV5zCrJY/rYYWTYDLuGkXScDBz5wIdx29XAzDZpfgUsALYBg4ErVPWIiKwB7oquL94AXADEz4t+o4hcG913a8s65fGIyBxgDkAoFKKioiJ2bNy4cQBs2bIlti8QCBAIBKisrKS5uRmIDJzJzMykpqam1QyThYWFNDY2snXr1ti+YDCI3+9v9Tk5OTmEQiGqq6tbrcJVXFxMXV1dq8nH8vPz8fl8rfpc+/1+gsEgVVVVsf8aMjMzKSoqIhwOEw6Hu+VUW1tLVVUVBQUFae+0Z88e/CJ8ejRcOCFE9rDjeeafG/jH+jC/fWMT/7N4EyMG9efMouEcF4DSUQPIzuznOqfa2lrC4XC73710q6fa2tpYGTr6e0oXJ1WloaGhS9cItzu11Et3rnstTh3h2HocInI5cL6q3hDdvgaYoarfiEvzeeBU4JtAIbAIOE5V94rIl4k8yqoncpfSoKq3iEgeECZyt/IjYJSqfqmzsth6HEcXexubeG39R7y0tobX1n9E/cFmBmRlcOYxucwqyeOc4pEMG9Q/1cU0DNfT0XocTt5xVANj4rZDRO4s4rkeuFsj0atSRDYDxcASVf0d8DsAEflJ9HyoamxtURH5DfC8YwYQ+2/QCxwtLkN8WVx03GguOm40B5sP889NtSwqr2FR+Q5eWFtDRj/hxIJhzCoJcl5JHmOGD+zj0n/M0VIn6Ya5dI6TvaqWAhNFZLyI9AeuJPJYKp4PgHMBoncSk4CWNpGR0Z9jgcuAJ6Pbo+LyXwqscdCh1e1runM0umRnRu40fnzJsbxz+7n89eunMvfMCdTuP8SPni/n9HteZfb9i/nlovdZs3UPfb0i5tFYJ+mAuXSOY3ccqtosIjcCLwIZwKOqulZE5kaPP0zkUdNjIrIaEOA2VW2xfCbaxtEEfD2uHeMeESkl8qiqCviqUw6Gt+jXTzhujJ/jxvj51vnFVIX3s6h8By+V1/Df/9jAg69sIN8/gE9PHsl5U4LMGD+crAwb6mQYbXHyURWquhBY2Gbfw3HvtwHndZD39A72X5PMMhpHLwWBQXzljAl85YwJhOsP8o91O3mpfAfzl37I4+9sYYgvk3OKRzKrJMiZk3LJyXb0z8Uw0gbHGsfdRG8axxsaGhgwYECSS5QazKVrHDjUzBsbwiwq38Er63aw+0AT/TP6cUrRCM4rCfLpySMZOSQ5U1VbnbgTc4mQisZxw0hLBvbP5PwpQc6fEqT58BGWb9nNS+U7WFS+gzueXc0dz8L0sZFBh+eVBCkamZPqIhtGn2IPcBMQ3+c53TGX7pOZ0Y+ZE0bwvQtLeP1bZ/HCzadz66xjaD6s3PPCej79y9c5597X+Onf17F8S22rNUO6gtWJOzGXzrE7DsPoIiJCcXAIxcEhfOPciWyra+DldZE7kd+9sZn/eX0TgZzsaON6HqcUBvBlZaS62IaRdCxwGEYPGe0fwLUnF3DtyQXsaWjitfU7WVS+g+dXbWf+0g8Z2L/1oEP/QBt0aHgDCxwJ8MogIDAXJxk6IIuLS/O5uDQ/NujwpbU1vLxuB39fExl0OKNgOOdNicyjFRoWGXToNo/eYC7uxAkX61VlGA5y5IiyauueyGSMa3ewYWdkPqKSUUOYFZ2MccroIWk1o69x9NBRryoLHAmorKykqKgoySVKDeaSejaH98emP1m2ZTeqkO8fEO2hlceJaTzoMF3rpD3MJYJ1x+0hLTNGegFzST3jA4OYc0Yhc84oJFx/kCdeXcnqWuHJJR/w2NtVDB2QFR10mMeZx+QyKI0GHaZrnbSHuXRO+nwrDcNjBHKyOX/iEOYVF3PgUDOL348OOqzYwbMrttI/sx+nFo7gvClBzp08kpGDkzPo0DB6iwWOBPh83vljNRf30eIxsH8ms6cGmT01Muhw2ZbdvLR2B4vW1fDqn1cjAtPH+CMz+kZXOnQbXqkTMJdEWBuHYbgYVWX9jn2RIFK+g9Vb9wAwIXcQ55UEIysdjvHTz1Y6NBzAGsd7GDhqamoIBoNJLlFqMBf30V2PlkGHL63dwT837aL5iBLIyWZWyUjOKwlycuGIlA069EqdgLm0YI3jPaSurs4zXyBzcR/d9Whv0OFL5TtYULaNJ5dEBh2eNSk66HBSHkMHZjlY+tZ4pU7AXBJhgcMw0pS2gw7f2biLl8p38HL5Dhaujgw6nDl+OOeV5DFrSpB8vzdmezVSj6MdxkVktoisF5FKEbm9neNDReQ5EVkpImtF5Pq4Y/NEZE10/81x+4eLyCIR2RD9OcxJB8NIB7IzMzhr0kh+cumx/PM75/KXr5/KV8+YwEf7DnLnc+Wcevc/uOCBN7j/5fdZu63vVzo0vIVjbRwikgG8D8wisl74UuAqVS2PS3MHMFRVbxORXGA9EASOAeYDM4BDwAvA11R1g4jcA9Sq6t3RYDRMVW/rrCy9aeNoamoiK6vvbvedxFzcR194tAw6fGntDpZ/0GbQ4ZQ8ZhQMJzMJgw69UidgLi2koo1jBlCpqi1riM8HLgbK49IoMFgi8y3kALVAMzAZ+KeqHojmfZ3I+uL3RM9xVjT/48BrQKeBozc0NjZ65gtkLu6jLzziBx1+tO8g/6iI9ND6Q9ygw3Ojgw7P6MWgQ6/UCZhLIpx8VJUPfBi3XR3dF8+viASJbcBqYJ6qHgHWAGeIyAgRGQhcAIyJ5slT1e0A0Z8jnVOArVu3Onn6PsVc3Edfe+QOzuaKE8fy2+tOpOy/ZvHwvx7PuZNH8o/1O/naE+8x/UeL+NJjS5m/5AM+2newW+f2Sp2AuSTCyTuO9jqWt30udj5QBpwDFAKLROQNVV0nIj8DFgH1wEoidyJd/3CROcAcgFAoREVFRezYuHHjgNYLnAQCAQKBAJWVlbEh+i0DZ2pqaqirq4ulLSwspLGxsVWFBINB/H5/q8/JyckhFApRXV1NfX19bH9xcTF1dXXU1NTE9uXn5+Pz+di4cWNsn9/vJxgMUlVVRWNjIwCZmZkUFRURDocJh8PdcgqHw1RVVVFQUJD2TrW1tbFy+Xy+tHVqOd7ed68vnAoy4QefKeSuiyaz4J1y/vnhft7+oJZ/VOxEZDVTRg5gZmgAJ48dRMGIgZ06hcPhWBk6+ntKl3pqbm6moaGhS9cItzu11Et3rnstTh3hZBvHycCdqnp+dPs7AKr607g0fwPuVtU3otv/AG5X1SVtzvUToFpVfy0i64GzVHW7iIwCXlPVSZ2VpTdtHBUVFRQXF/cor9swF/fhRg9VpaJmX2zk+pqtewEozB3EeVMigw5LQ58cdOhGl55iLhFS0caxFJgoIuOBrcCVwBfbpPkAOBd4Q0TygElAS5vISFXdKSJjgcuAk6N5FgDXAXdHf/7VQQfP9OUGc3EjbvQQESaPGsLkUUOY9+mJbK1r4OXyHbxUXsNvFm/i/722kdzB2Xx6cl50pcMRZGdmuNKlp5hL5zg6clxELgDuBzKAR1X1LhGZC6CqD4vIaOAxYBSRR1t3q+rvo3nfAEYATcA3VfWV6P4RwNPAWCKB53JVre2sHDbliGEkhz0Hmnjt/Z28tHYHr63fyf5DhxnUP4MzJ+Vy9qSRnDRhBKFhA2x9EY9gU47YoypzcSHp7HGw+TBvb9zFovJIL62WxvTRQ33MGD+cGeNHMGP8cApzB6VdIEnnemlLuj2qMgzDw2RnZnD2pJGcPWkkP754Ki+9u4qPGMq7m2t5a+Mu/lK2DYARg/pHA0nkVRwcQoZNypjWWOAwDKPX9OsnFAzLZnZxAdecXICqUrXrAEs27+LdzbUs2VzL39dEeukM8WVyYsHHgWRq/tC0XfXwaMUCRwJycty37kFPMRf34RUPaO0iIowPDGJ8YBBXnDgWgK11DSzdXMu7m2t5d/MuXqnYCcCArAyOHzcsFkhKx/hTNsNvC16tl2RhbRyGYaSEj/YdZGlV5G7k3c21VNTsRRX6Z/SjdIw/Fkg+NW4YOWm0hK6XsMbxHgaO6upqQqFQkkuUGszFfXjFA3rvsudAE8u2fBxIVm/dw+EjSkY/YeroIbEG9xMLhuEf2D+JJf8kVi8RrHG8h8SP5kx3zMV9eMUDeu8ydGAW507O49zJeQDsP9jMex/sjgWSx9/Zwm/e2AxAcXAwM8YPZ+b4EZw4fljS12O3eukcCxyGYbiSQdmZnD4xl9Mn5gLQ2HSYVdV7Yg3uf1pezf+9E5k+Y0JgUKueW6FhA1NZdM9jgcMwjLTAl5URCww3Ak2Hj1C+bS/vbt7Fks21LFy9nflLI/Oq5vsHxNLOHD+c8YH0G0viZqyNwzAMT3DkiLJ+xz6WbP64nSRcHxmUGMjJZmbcHcmkvMGfmGvL+CTWON7DwFFXV4ff709ugVKEubgPr3iA+1xUlc3h/bFxJO9u2sW2PZEZZIf4MuMebY1gyughrcaSuM2lN/TGxRrHe0hNTY1nvkDm4j684gHucxERJuTmMCE3h6tmRMaSVO8+ELsjWbK5lpfXRcaSDOwfGUsyMxpIfPvd5dIbnKgXCxyGYRw1hIYNJDRsIJd9KtI9dee+RpZu3h1rJ7n3pfcByOonTB+3J/Z461Njh/V4ZUQvYr8JwzCOWkYO9vHZaaP47LRRANQdOMTSqt28sHwDlXsO8+vXNvLf/6iMjCXJH8pJ0UBywrjhDB3ojaVle4K1cSRg3759DB48OMklSg3m4j684gHedKk/2Mx7W3bHHm2VfVjHocNHEIHi4JDYHcmJBcPJHZyd6mK3S2/qxRrHexg4mpqaPLNovbm4D694wNHh0th0mLIP62KBZPmW3TQ0HQZgQu4gZo4fEQsmo/0D+rrY7dKberHG8R6yceNGz8zLby7uwysecHS4+LIyOGnCCE6aMAKIjCVZs3VPLJA8v2obTy75AIDQsAGxcSQzxo+gYMTAlIwlcaJeHA0cIjIbeIDICoC/VdW72xwfCvyeyGp+mcC9qvq/0WO3ADcACqwGrlfVRhG5E/gK8FH0NHeo6kInPQzDMNojK6Mf08cOY/rYYXz1zEIOH1EqavbGAsnr6z/iz+9tBSB3cHYskMwcP4KJI3PSdiyJY4FDRDKAh4BZQDWwVEQWqGp5XLKvA+Wq+jkRyQXWi8gTQC5wE1Ciqg0i8jSRNcsfi+a7T1XvdarshmEYPSGjnzBl9FCmjB7K9aeOR1XZ+NH+aCCJTJXyt1XbAfAPzOLEguGxR1slo4aQmSbrkjh5xzEDqFTVTQAiMh+4GIgPHAoMlsj9Ww5QCzTHlW2AiDQBA4FtDpa1Q7zSlxvMxY14xQPMpT1EhKKRORSNzOGLM8eiqlTvbogOSox0AV5UvgOAQf0zOD4ukEwLDSU7s/frkjhRL04Gjnzgw7jtamBmmzS/AhYQCQqDgStU9QiwVUTuBT4AGoCXVPWluHw3isi1wDLgVlXd3fbDRWQOMAcgFApRUVEROzZu3DgAtmzZEtsXCAQIBAJUVlbS3ByJXT6fj4KCAmpqaqirq4ulLSwspLGxka1bt8b2BYNB/H5/q8/JyckhFApRXV3daobK4uJi6urqqKmp+fiXlZ+Pz+dj48aNsX1+v59gMEhVVRWNjZERr5mZmRQVFREOhwmHw912amxs9IRTfX19rFzpXk+ZmZme+O7V1dXFyuqFv6eGhgZHrhH7d37A1EEwdWo2N500kawhAV5YvoGlW+pYU7OHxe9HnsJnZ/ZjUqA/x+YNYGqej3OOm8DwIYN65FRXV9ej615HONarSkQuB85X1Rui29cAM1T1G3FpPg+cCnwTKAQWAccRaRN5BrgCqAP+CPxJVX8vInlAmMjdyo+AUar6pc7K0pteVVVVVRQUFPQor9swF/fhFQ8wl2Sxe/8hllR9PLp97bY9HFHI7CccGxoaayc5ftxwhg5I3FuqNy6p6FVVDYyJ2w7xycdN1wN3ayR6VYrIZqAYGAdsVtWPAETkz8ApwO9VdUdLZhH5DfC8cwrEorgXMBf34RUPMJdkMWxQf86fEuT8KUEA9jU2sTxuLMmjb27mf17fhAhMDg5h5oRIIDmxYDgjcj45lsQJFycDx1JgooiMB7YSadz+Yps0HwDnAm9E7yQmAZsAAU4SkYFEHlWdS+SxFCIySlW3R/NfCqxx0MEwDCOlDPZlcdakkZw1aSQQGUuy4oO66AzAu3hyyQf871tVABSNzInrAjycUUOdGUviWOBQ1WYRuRF4kcijp0dVda2IzI0ef5jIo6bHRGQ1kWBxm6qGgbCI/Al4j0hj+Qrgkeip7xGRUiKPqqqArzrlAJHnhV7BXNyHVzzAXPoKX1YGJxeO4OTCEcBEDjUfYXVsLMkunivbxh/ejYwlGTN8APNOCpDs4TU2ctwwDMNDHD6irNv+8ViSb8+exITcnB6dq6M2jvToNJxC4ntapDvm4j684gHm4hZaJmT80mnjefia4xkiyW/jsMCRgHT+ArXFXNyHVzzAXNyKEy4WOAzDMIxuYYHDMAzD6BYWOBLQMtrSC5iL+/CKB5iLW3HCxQKHYRiG0S0scCQgfl6XdMdc3IdXPMBc3IoTLhY4DMMwjG5hgcMwDMPoFkfFyHER+Qjo6f1agMhsvF7AXNyHVzzAXNxKb1zGqWpu251HReDoDSKyrL0h9+mIubgPr3iAubgVJ1zsUZVhGIbRLSxwGIZhGN3CAkdiHkmcJG0wF/fhFQ8wF7eSdBdr4zAMwzC6hd1xGIZhGN3CAodhGIbRLSxwRBGR2SKyXkQqReT2do6LiDwYPb5KRD6VinJ2hS64nCUie0SkLPr6r1SUMxEi8qiI7BSRdteVT5c66YJHWtQHgIiMEZFXRWSdiKwVkXntpEmXeumKi+vrRkR8IrJERFZGPX7QTprk1omqHvUvImuibwQmAP2BlUBJmzQXAH8nsjb6ScC7qS53L1zOAp5PdVm74HIG8ClgTQfH06VOEnmkRX1EyzoK+FT0/WDg/TT+W+mKi+vrJvp7zom+zwLeBU5ysk7sjiPCDKBSVTep6iFgPnBxmzQXA/+nEf4J+EVkVF8XtAt0xSUtUNXFQG0nSdKiTrrgkTao6nZVfS/6fh+wDshvkyxd6qUrLq4n+nuuj25mRV9tez0ltU4scETIBz6M267mk1+grqRxA10t58nRW9u/i8iUvila0kmXOukKaVcfIlIATCfyH248aVcvnbhAGtSNiGSISBmwE1ikqo7WSWZPM3oMaWdf24jdlTRuoCvlfI/IHDT1InIB8BdgotMFc4B0qZNEpF19iEgO8Axws6rubXu4nSyurZcELmlRN6p6GCgVET/wrIhMVdX4NrWk1ondcUSoBsbEbYeAbT1I4wYSllNV97bc2qrqQiBLRAJ9V8SkkS510inpVh8ikkXkQvuEqv65nSRpUy+JXNKtblS1DngNmN3mUFLrxAJHhKXARBEZLyL9gSuBBW3SLACujfZOOAnYo6rb+7qgXSChi4gERUSi72cQ+R7s6vOS9p50qZNOSaf6iJbzd8A6Vf1lB8nSol664pIOdSMiudE7DURkAPBpoKJNsqTWiT2qAlS1WURuBF4k0ivpUVVdKyJzo8cfBhYS6ZlQCRwArk9VeTujiy6fB74mIs1AA3ClRrteuAkReZJIr5aAiFQD3yfS8JdWddIFj7SojyinAtcAq6PP1AHuAMZCetULXXNJh7oZBTwuIhlEAtvTqvq8k9cvm3LEMAzD6Bb2qMowDMPoFhY4DMMwjG5hgcMwDMPoFhY4DMMwjG5hgcMwDMPoFhY4DCMJiMjhuBlUy6SdWYl7ce4C6WBmXcNIBTaOwzCSQ4Oqlqa6EIbRF9gdh2E4iIhUicjPouslLBGRouj+cSLySnRthFdEZGx0f56IPBudVG+liJwSPVWGiPwmut7CS9ERwoaREixwGEZyGNDmUdUVccf2quoM4FfA/dF9vyIyzfU04Angwej+B4HXVfU4Imt4rI3unwg8pKpTgDrgXxy1MYxOsJHjhpEERKReVXPa2V8FnKOqm6IT6tWo6ggRCQOjVLUpun+7qgZE5CMgpKoH485RQGSq7InR7duALFX9cR+oGcYnsDsOw3Ae7eB9R2na42Dc+8NY+6SRQixwGIbzXBH3853o+7eJzFwMcDXwZvT9K8DXILY4z5C+KqRhdBX7r8UwksOAuBlWAV5Q1ZYuudki8i6Rf9Suiu67CXhURL4FfMTHs5XOAx4RkS8TubP4GuC6KcmNoxtr4zAMB4m2cZygquFUl8UwkoU9qjIMwzC6hd1xGIZhGN3C7jgMwzCMbmGBwzAMw+gWFjgMwzCMbmGBwzAMw+gWFjgMwzCMbvH/A8WzpfrDRJi1AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.iter\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.beta_1\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.beta_2\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.decay\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.learning_rate\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-0.embeddings\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-2.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-3.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-3.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-4.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-4.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-1.cell.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-1.cell.recurrent_kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-1.cell.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-0.embeddings\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-2.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-3.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-3.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-4.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-4.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-1.cell.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-1.cell.recurrent_kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-1.cell.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).layer-6\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.iter\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.beta_1\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.beta_2\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.decay\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.learning_rate\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-0.embeddings\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-2.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-3.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-3.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-4.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-4.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-1.cell.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-1.cell.recurrent_kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-1.cell.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-0.embeddings\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-2.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-3.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-3.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-4.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-4.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-1.cell.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-1.cell.recurrent_kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-1.cell.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.iter\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.beta_1\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.beta_2\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.decay\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.learning_rate\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-0.embeddings\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-2.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-3.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-3.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-4.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-4.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-1.cell.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-1.cell.recurrent_kernel\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-1.cell.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-0.embeddings\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-2.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-3.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-3.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-4.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-4.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-1.cell.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-1.cell.recurrent_kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-1.cell.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "Model: \"sequential_11\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_11 (Embedding)     (1, None, 256)            3262208   \n",
      "_________________________________________________________________\n",
      "gru_11 (GRU)                 (1, None, 1024)           3938304   \n",
      "_________________________________________________________________\n",
      "dense_41 (Dense)             (1, None, 1024)           1049600   \n",
      "_________________________________________________________________\n",
      "dense_42 (Dense)             (1, None, 512)            524800    \n",
      "_________________________________________________________________\n",
      "dense_43 (Dense)             (1, None, 256)            131328    \n",
      "_________________________________________________________________\n",
      "dense_44 (Dense)             (1, None, 256)            65792     \n",
      "_________________________________________________________________\n",
      "dense_45 (Dense)             (1, None, 512)            131584    \n",
      "_________________________________________________________________\n",
      "dense_46 (Dense)             (1, None, 12743)          6537159   \n",
      "=================================================================\n",
      "Total params: 15,640,775\n",
      "Trainable params: 15,640,775\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "def render_training_history(training_history):\n",
    "    loss = training_history.history['loss']\n",
    "\n",
    "    plt.title('Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.plot(loss, label='Training set')\n",
    "    plt.legend()\n",
    "    plt.grid(linestyle='--', linewidth=1, alpha=0.5)\n",
    "    plt.show()\n",
    "\n",
    "render_training_history(history)\n",
    "\n",
    "tf.train.latest_checkpoint(checkpoint_dir)\n",
    "\n",
    "simplified_batch_size = 1\n",
    "\n",
    "model_simplified = build_vae2_model(VOCABULARY_SIZE,256, 1024, 128, simplified_batch_size)#64\n",
    "model_simplified.load_weights(tf.train.latest_checkpoint(checkpoint_dir))\n",
    "model_simplified.build(tf.TensorShape([simplified_batch_size, None]))\n",
    "\n",
    "model_simplified.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "premier-voice",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_text(model, start_string, num_generate = 100, temperature=1.0):\n",
    "    #padded_start_string = start_string + ' '\n",
    "    input_indices = np.array(tokenizer.texts_to_sequences([start_string]))\n",
    "    #print(input_indices,len(input_indices[0]))\n",
    "    #for val in range(MAX_PROC_RECIPE_LENGTH-len(input_indices[0])):\n",
    "    #    input_indices = np.append(input_indices,tokenizer.texts_to_sequences([STOP_SIGN])[0])\n",
    "    #print(input_indices)\n",
    "    text_generated = []\n",
    "    model.reset_states()\n",
    "    predictions = model(input_indices)\n",
    "    #print(\"here\",predictions)\n",
    "    predictions = tf.squeeze(predictions, 0)\n",
    "    out_arr = np.array([[]])\n",
    "    for pR in range(num_generate):\n",
    "        pVal = int(np.argmax(predictions[pR]))\n",
    "        if pVal != 7962:\n",
    "            out_arr = np.append(out_arr,int(pVal))\n",
    "        #print(np.argmax(predictions[pR]))\n",
    "    predictions = predictions / temperature\n",
    "    predicted_id = tf.random.categorical(\n",
    "            predictions,\n",
    "            num_samples=1\n",
    "            ).numpy()\n",
    "    #print(predicted_id.shape)\n",
    "    #input_indices = tf.expand_dims([predicted_id], 0)\n",
    "    #next_character = tokenizer.sequences_to_texts(input_indices.numpy())\n",
    "    out_arr = np.array([out_arr])\n",
    "    #next_character = tokenizer.sequences_to_texts(out_arr)#predictions)#predicted_id\n",
    "    next_character = tokenizer.sequences_to_texts(predicted_id)\n",
    "    text_generated.extend(next_character)\n",
    "    return text_generated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "experimental-update",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_text(model, start_string, num_generate = 100, temperature=1.0):\n",
    "    padded_start_string = STOP_WORD_TITLE + start_string\n",
    "    input_indices = np.array(tokenizer.texts_to_sequences([padded_start_string]))\n",
    "    print(input_indices,\"!!!\")\n",
    "    text_generated = []\n",
    "    # Here batch size == 1.\n",
    "    model.reset_states()\n",
    "    for char_index in range(num_generate):\n",
    "        predictions = model(input_indices)\n",
    "        # remove the batch dimension\n",
    "        predictions = tf.squeeze(predictions, 0)\n",
    "        # Using a categorical distribution to predict the character returned by the model.\n",
    "        predictions = predictions / temperature\n",
    "        predicted_id = tf.random.categorical(\n",
    "            predictions,\n",
    "            num_samples=1\n",
    "        )[-1, 0].numpy()\n",
    "        input_indices = tf.expand_dims([predicted_id], 0)\n",
    "        next_character = tokenizer.sequences_to_texts(input_indices.numpy())[0]\n",
    "        text_generated.append(next_character)\n",
    "    return (padded_start_string+ ' ' + ' '.join(text_generated))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "intended-worst",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attempt: \"2 cups rolled oats 3 4 cup packed brown sugar 1 2 cup wheat germ 3 4 teaspoon ground cinnamon 1 cup all purpose flour 3 4 cup raisins optional 3 4 teaspoon salt 1 2 cup honey 1 egg beaten 1 2 cup vegetable oil 2 teaspoons vanilla extract ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£\" + 1.0\n",
      "-----------------------------------\n",
      "['cups', 'cold', 'oats', '3', '4', 'cup', 'granulated', 'cashew', 'milk', '1', '2', 'cup', 'white', 'germ', '1', '2', 'teaspoon', 'ground', 'cinnamon', '1', 'cup', 'all', 'purpose', 'cocoa', '1', '2', 'cup', 'chopped', '1', '1', '4', 'teaspoon', 'baking', '1', '2', 'cup', 'seeds', '2', 'large', 'whites', '1', '4', 'cup', 'brown', 'oil', '1', 'teaspoons', 'vegetable', 's', '‚ê£', '‚ê£', '‚ê£', '‚ê£', '‚ê£', '‚ê£', '‚ê£', '‚ê£', '‚ê£', '‚ê£', '‚ê£', '‚ê£', '‚ê£', '‚ê£', '‚ê£', '‚ê£', '‚ê£', '‚ê£', '‚ê£', '‚ê£', '‚ê£', '‚ê£', '‚ê£', '‚ê£', '‚ê£', '‚ê£', '‚ê£', '‚ê£', '‚ê£', '‚ê£', '‚ê£']\n",
      "\n",
      "\n",
      "\n",
      "Attempt: \"2 cups rolled oats 3 4 cup packed brown sugar 1 2 cup wheat germ 3 4 teaspoon ground cinnamon 1 cup all purpose flour 3 4 cup raisins optional 3 4 teaspoon salt 1 2 cup honey 1 egg beaten 1 2 cup vegetable oil 2 teaspoons vanilla extract ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£\" + 0.8\n",
      "-----------------------------------\n",
      "['cups', 'pecans', 'oats', '1', '4', 'cup', 'packed', 'brown', 'rice', '1', '4', 'cup', 'unsweetened', 'germ', '3', '4', 'teaspoon', 'ground', 'extract', '1', 'cup', 'all', 'purpose', 'flour', '1', '4', 'cup', 'sugar', 'beaten', '1', '2', 'teaspoons', 'almonds', '1', '4', 'cup', 'sugar', '1', 'eggs', 'eggs', '1', '4', 'cup', 'vegetable', 'oil', '1', 'tablespoons', 'brown', 'needed', '‚ê£', '‚ê£', '‚ê£', '‚ê£', '‚ê£', '‚ê£', '‚ê£', '‚ê£', '‚ê£', '‚ê£', '‚ê£', '‚ê£', '‚ê£', '‚ê£', '‚ê£', '‚ê£', '‚ê£', '‚ê£', '‚ê£', '‚ê£', '‚ê£', '‚ê£', '‚ê£', '‚ê£', '‚ê£', '‚ê£', '‚ê£', '‚ê£', '‚ê£', '‚ê£', '‚ê£']\n",
      "\n",
      "\n",
      "\n",
      "Attempt: \"2 cups rolled oats 3 4 cup packed brown sugar 1 2 cup wheat germ 3 4 teaspoon ground cinnamon 1 cup all purpose flour 3 4 cup raisins optional 3 4 teaspoon salt 1 2 cup honey 1 egg beaten 1 2 cup vegetable oil 2 teaspoons vanilla extract ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£\" + 0.4\n",
      "-----------------------------------\n",
      "['cups', 'rolled', 'oats', '1', '4', 'cup', 'packed', 'brown', 'sugar', '1', '2', 'cup', 'raw', 'germ', '1', '2', 'teaspoon', 'almond', 'extract', '1', 'cup', 'all', 'purpose', 'flour', '1', '4', 'cup', 'raisins', 'powder', '1', '4', 'teaspoon', 'ginger', '1', '2', 'cup', 'sugar', '3', 'egg', 'egg', '1', '2', 'cup', 'vegetable', 'flour', '1', 'teaspoons', 'vegetable', 'cinnamon', '‚ê£', '‚ê£', '‚ê£', '‚ê£', '‚ê£', '‚ê£', '‚ê£', '‚ê£', '‚ê£', '‚ê£', '‚ê£', '‚ê£', '‚ê£', '‚ê£', '‚ê£', '‚ê£', '‚ê£', '‚ê£', '‚ê£', '‚ê£', '‚ê£', '‚ê£', '‚ê£', '‚ê£', '‚ê£', '‚ê£', '‚ê£', '‚ê£', '‚ê£', '‚ê£', '‚ê£']\n",
      "\n",
      "\n",
      "\n",
      "Attempt: \"2 cups rolled oats 3 4 cup packed brown sugar 1 2 cup wheat germ 3 4 teaspoon ground cinnamon 1 cup all purpose flour 3 4 cup raisins optional 3 4 teaspoon salt 1 2 cup honey 1 egg beaten 1 2 cup vegetable oil 2 teaspoons vanilla extract ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£\" + 0.2\n",
      "-----------------------------------\n",
      "['cups', 'milk', 'oats', '3', '4', 'cup', 'granulated', 'brown', 'sugar', '1', '2', 'cup', 'raw', 'germ', '1', '2', 'teaspoon', 'ground', 'extract', '1', 'cup', 'all', 'purpose', 'flour', '1', '4', 'cup', 'raisins', 'powder', '1', '2', 'teaspoon', 'ginger', '1', '2', 'cup', 'sugar', '1', 'large', 'beaten', '1', '2', 'cup', 'sour', 'oil', '1', 'teaspoon', 'vegetable', 'oil', '‚ê£', '‚ê£', '‚ê£', '‚ê£', '‚ê£', '‚ê£', '‚ê£', '‚ê£', '‚ê£', '‚ê£', '‚ê£', '‚ê£', '‚ê£', '‚ê£', '‚ê£', '‚ê£', '‚ê£', '‚ê£', '‚ê£', '‚ê£', '‚ê£', '‚ê£', '‚ê£', '‚ê£', '‚ê£', '‚ê£', '‚ê£', '‚ê£', '‚ê£', '‚ê£', '‚ê£']\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def generate_combinations(model):\n",
    "    recipe_length = 80\n",
    "    #try_letters = ['', '\\n', 'A', 'B', 'C', 'O', 'L', 'Mushroom', 'Apple', 'Slow', 'Christmass', 'The', 'Banana', 'Homemade']\n",
    "    try_letters = ['beef pineapple']# 'Apple', 'Slow', 'Christmass', 'The', 'Banana', 'Homemade']\n",
    "    try_temperature = [1.0, 0.8, 0.4, 0.2]\n",
    "    test = np.array([dataset_vectorized_padded[298]])\n",
    "    #test[0] = test[0,0:79]\n",
    "    test = np.array([test[0][0:80]])\n",
    "    try_letters = tokenizer.sequences_to_texts(test)\n",
    "    \n",
    "    for letter in try_letters:\n",
    "        for temperature in try_temperature:\n",
    "            generated_text = generate_text(\n",
    "                model,\n",
    "                start_string=letter,\n",
    "                num_generate = recipe_length,\n",
    "                temperature=temperature\n",
    "            )\n",
    "            print(f'Attempt: \"{letter}\" + {temperature}')\n",
    "            print('-----------------------------------')\n",
    "            print(generated_text)\n",
    "            print('\\n\\n')\n",
    "\n",
    "generate_combinations(model_simplified)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "every-continuity",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['slice cheddar optional banana favorite sliced banana']"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = np.array([[ 523., 163.,  99., 450., 742.,  28., 450.]])\n",
    "tokenizer.sequences_to_texts(test)\n",
    "#model.predict(dataset_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "together-hurricane",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1479]] !!!\n",
      "Attempt: \"guava\" + 1.0\n",
      "-----------------------------------\n",
      "üìó guavapaste 4 cardamom pods 1 dozen large eggs 2 jumbo yolks 1 egg white 1 cup sugar ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£\n",
      "\n",
      "\n",
      "\n",
      "[[1479]] !!!\n",
      "Attempt: \"guava\" + 0.8\n",
      "-----------------------------------\n",
      "üìó guavawater or jam 4 tablespoons unsalted butter 1 4 cup granulated sugar 3 4 cup all purpose flour 1 2 cup rolled oats ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£\n",
      "\n",
      "\n",
      "\n",
      "[[1479]] !!!\n",
      "Attempt: \"guava\" + 0.4\n",
      "-----------------------------------\n",
      "üìó guavapaste 1 4 cup sugar 1 2 cup water 1 cup sugar 1 cup water ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£\n",
      "\n",
      "\n",
      "\n",
      "[[1479]] !!!\n",
      "Attempt: \"guava\" + 0.2\n",
      "-----------------------------------\n",
      "üìó guavapaste 1 4 cup sugar 1 4 cup water 1 4 cup fresh lime juice 1 4 cup fresh lime juice 1 4 cup sugar 1 4 cup water ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def generate_combinations(model):\n",
    "    recipe_length = 80\n",
    "    #try_letters = ['', '\\n', 'A', 'B', 'C', 'O', 'L', 'Mushroom', 'Apple', 'Slow', 'Christmass', 'The', 'Banana', 'Homemade']\n",
    "    try_letters = ['guava']# 'Apple', 'Slow', 'Christmass', 'The', 'Banana', 'Homemade']\n",
    "    try_temperature = [1.0, 0.8, 0.4, 0.2]\n",
    "    #test = np.array([dataset_vectorized_padded[298]])\n",
    "    #test[0] = test[0,0:79]\n",
    "    #test = np.array([test[0][0:80]])\n",
    "    #try_letters = tokenizer.sequences_to_texts(test)\n",
    "    \n",
    "    for letter in try_letters:\n",
    "        for temperature in try_temperature:\n",
    "            generated_text = generate_text(\n",
    "                model,\n",
    "                start_string=letter,\n",
    "                num_generate = recipe_length,\n",
    "                temperature=temperature\n",
    "            )\n",
    "            print(f'Attempt: \"{letter}\" + {temperature}')\n",
    "            print('-----------------------------------')\n",
    "            print(generated_text)\n",
    "            print('\\n\\n')\n",
    "\n",
    "generate_combinations(model_simplified)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "94f80b19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1479]] !!!\n",
      "Attempt: \"guava\" + 1.0\n",
      "-----------------------------------\n",
      "üìó guava oil or reserved meat salad mix ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£\n",
      "\n",
      "\n",
      "\n",
      "[[1479]] !!!\n",
      "Attempt: \"guava\" + 0.8\n",
      "-----------------------------------\n",
      "üìó guava paste 1 2 cup olive oil 2 tablespoons orange juice 1 tablespoon white sugar ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£\n",
      "\n",
      "\n",
      "\n",
      "[[1479]] !!!\n",
      "Attempt: \"guava\" + 0.4\n",
      "-----------------------------------\n",
      "üìó guava paste 2 cups vegetable oil 2 cups all purpose flour 2 teaspoons baking powder 1 2 teaspoon salt 1 egg beaten 1 2 cup milk plus more if needed 2 tablespoons grated parmesan cheese 1 4 cup grated ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£\n",
      "\n",
      "\n",
      "\n",
      "[[1479]] !!!\n",
      "Attempt: \"guava\" + 0.2\n",
      "-----------------------------------\n",
      "üìó guava paste 1 2 cup light brown sugar 1 2 cup chopped macadamia nuts 1 2 cup chopped roasted peanuts ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£ ‚ê£\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def generate_combinations(model):\n",
    "    recipe_length = 80\n",
    "    #try_letters = ['', '\\n', 'A', 'B', 'C', 'O', 'L', 'Mushroom', 'Apple', 'Slow', 'Christmass', 'The', 'Banana', 'Homemade']\n",
    "    try_letters = ['guava']# 'Apple', 'Slow', 'Christmass', 'The', 'Banana', 'Homemade']\n",
    "    try_temperature = [1.0, 0.8, 0.4, 0.2]\n",
    "    #test = np.array([dataset_vectorized_padded[298]])\n",
    "    #test[0] = test[0,0:79]\n",
    "    #test = np.array([test[0][0:80]])\n",
    "    #try_letters = tokenizer.sequences_to_texts(test)\n",
    "    \n",
    "    for letter in try_letters:\n",
    "        for temperature in try_temperature:\n",
    "            generated_text = generate_text(\n",
    "                model,\n",
    "                start_string=letter,\n",
    "                num_generate = recipe_length,\n",
    "                temperature=temperature\n",
    "            )\n",
    "            print(f'Attempt: \"{letter}\" + {temperature}')\n",
    "            print('-----------------------------------')\n",
    "            print(generated_text)\n",
    "            print('\\n\\n')\n",
    "\n",
    "generate_combinations(model_simplified)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d63145c1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
